/**
 * WebSocket STT Composable
 *
 * ë°±ì—”ë“œ WebSocket ê¸°ë°˜ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹(STT) ì²˜ë¦¬
 *
 * ì£¼ìš” ê¸°ëŠ¥:
 * - WebSocket ì—°ê²° ê´€ë¦¬
 * - ë§ˆì´í¬ ì…ë ¥ ìŠ¤íŠ¸ë¦¬ë°
 * - ì‹¤ì‹œê°„ STT ê²°ê³¼ ìˆ˜ì‹ 
 * - í™”ì ë¶„ë¦¬ ì§€ì›
 *
 * @see backend-python/app/api/voice_stt.py
 */
import { ref, onUnmounted } from 'vue'
import { createSTTStream } from '../services/voiceService'

export function useWebSocketSTT() {
  // ìƒíƒœ
  const isConnected = ref(false)
  const isRecording = ref(false)
  const error = ref(null)

  // STT ê²°ê³¼
  const recognizingText = ref('')  // ì¤‘ê°„ ì¸ì‹ ê²°ê³¼
  const recognizedText = ref('')   // ìµœì¢… ì¸ì‹ ê²°ê³¼
  const speakerId = ref(null)      // í™”ì ID
  const confidence = ref(0)        // ì‹ ë¢°ë„

  // WebSocket ë° MediaRecorder
  let wsConnection = null
  let mediaRecorder = null
  let audioStream = null

  /**
   * WebSocket ì—°ê²° ë° ë…¹ìŒ ì‹œì‘
   *
   * @param {string} language - BCP-47 ì–¸ì–´ ì½”ë“œ (ì˜ˆ: ko-KR, en-US)
   * @param {boolean} enableDiarization - í™”ì ë¶„ë¦¬ í™œì„±í™”
   * @param {Object} callbacks - ì¶”ê°€ ì½œë°± í•¨ìˆ˜ (ì„ íƒì‚¬í•­)
   * @param {Function} callbacks.onRecognizing - ì¤‘ê°„ ì¸ì‹ ê²°ê³¼ ì½œë°±
   * @param {Function} callbacks.onRecognized - ìµœì¢… ì¸ì‹ ê²°ê³¼ ì½œë°±
   * @returns {Promise<void>}
   */
  async function startRecording(language = 'ko-KR', enableDiarization = true, callbacks = {}) {
    try {
      error.value = null

      // 1. ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ë° ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ íšë“
      console.log('ğŸ¤ Requesting microphone access...')
      audioStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,      // Azure STT ê¶Œì¥: 16kHz
          channelCount: 1,        // ëª¨ë…¸
          echoCancellation: true, // ì—ì½” ì œê±°
          noiseSuppression: true  // ë…¸ì´ì¦ˆ ê°ì†Œ
        }
      })

      console.log('âœ… Microphone access granted')

      // 2. WebSocket ì—°ê²° ìƒì„±
      console.log('ğŸ”Œ Connecting to WebSocket STT...')
      wsConnection = createSTTStream(language, enableDiarization, {
        onRecognizing: (message) => {
          recognizingText.value = message.text || ''
          console.log('ğŸ”„ Recognizing:', message.text)

          // ì‚¬ìš©ì ì •ì˜ ì½œë°± í˜¸ì¶œ
          if (callbacks.onRecognizing) {
            callbacks.onRecognizing(message)
          }
        },

        onRecognized: (message) => {
          recognizedText.value = message.text || ''
          speakerId.value = message.speaker_id || 'Unknown'
          confidence.value = message.confidence || 0
          recognizingText.value = '' // ì¤‘ê°„ ê²°ê³¼ ì´ˆê¸°í™”

          console.log('âœ… Recognized:', message.text, `(Speaker: ${message.speaker_id})`)

          // ì‚¬ìš©ì ì •ì˜ ì½œë°± í˜¸ì¶œ
          if (callbacks.onRecognized) {
            callbacks.onRecognized(message)
          }
        },

        onError: (errorMessage) => {
          error.value = errorMessage
          console.error('âŒ STT error:', errorMessage)
        },

        onEnd: () => {
          isConnected.value = false
          console.log('ğŸ”š STT stream ended')
        }
      })

      isConnected.value = true

      // 3. MediaRecorder ìƒì„± (ì˜¤ë””ì˜¤ ì²­í¬ ìŠ¤íŠ¸ë¦¬ë°)
      // WAV ë˜ëŠ” Opus í˜•ì‹ìœ¼ë¡œ ì¸ì½”ë”©
      const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus')
        ? 'audio/webm;codecs=opus'
        : 'audio/webm'

      mediaRecorder = new MediaRecorder(audioStream, {
        mimeType,
        audioBitsPerSecond: 16000 // 16kbps
      })

      // ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹  ì‹œ WebSocketìœ¼ë¡œ ì „ì†¡
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0 && wsConnection) {
          wsConnection.send(event.data)
        }
      }

      // ë…¹ìŒ ì‹œì‘ (100msë§ˆë‹¤ ì²­í¬ ì „ì†¡)
      mediaRecorder.start(100)
      isRecording.value = true

      console.log('ğŸ”´ Recording started')

    } catch (err) {
      console.error('âŒ Failed to start recording:', err)
      error.value = err.message
      throw err
    }
  }

  /**
   * ë…¹ìŒ ë° WebSocket ì—°ê²° ì¢…ë£Œ
   */
  function stopRecording() {
    try {
      // MediaRecorder ì¤‘ì§€
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop()
        console.log('â¹ï¸ MediaRecorder stopped')
      }

      // ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ í•´ì œ
      if (audioStream) {
        audioStream.getTracks().forEach(track => track.stop())
        console.log('ğŸ”‡ Audio stream released')
      }

      // WebSocket ì—°ê²° ì¢…ë£Œ
      if (wsConnection) {
        wsConnection.close()
        console.log('ğŸ”Œ WebSocket closed')
      }

      isRecording.value = false
      isConnected.value = false

    } catch (err) {
      console.error('âŒ Failed to stop recording:', err)
      error.value = err.message
    }
  }

  /**
   * ê²°ê³¼ ì´ˆê¸°í™”
   */
  function clearResults() {
    recognizingText.value = ''
    recognizedText.value = ''
    speakerId.value = null
    confidence.value = 0
    error.value = null
  }

  // Cleanup on unmount
  onUnmounted(() => {
    if (isRecording.value) {
      stopRecording()
    }
  })

  return {
    // ìƒíƒœ
    isConnected,
    isRecording,
    error,

    // STT ê²°ê³¼
    recognizingText,
    recognizedText,
    speakerId,
    confidence,

    // ë©”ì„œë“œ
    startRecording,
    stopRecording,
    clearResults
  }
}
