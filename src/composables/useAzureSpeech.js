/**
 * Azure Speech Composable
 *
 * Azure Speech SDKë¥¼ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ ë° ë²ˆì—­ ì²˜ë¦¬
 *
 * ì£¼ìš” ê¸°ëŠ¥:
 * - ë§ˆì´í¬ë¥¼ í†µí•œ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹
 * - ëª©í‘œ ì–¸ì–´ë¡œ ë™ì‹œ ë²ˆì—­
 * - ë¶€ë¶„(ì¸ì‹ ì¤‘) ë° ìµœì¢…(ì¸ì‹ ì™„ë£Œ) ê²°ê³¼ ì œê³µ
 * - VAD (ìŒì„± í™œë™ ê°ì§€) ì„¤ì •
 * - íŠ¹ì • ìš©ì–´ ì¸ì‹ë¥  í–¥ìƒì„ ìœ„í•œ êµ¬ë¬¸ ëª©ë¡ ì§€ì›
 * - ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì—°ê²°
 *
 * @see https://learn.microsoft.com/azure/ai-services/speech-service/
 */
import { ref, computed } from 'vue'
import * as SpeechSDK from 'microsoft-cognitiveservices-speech-sdk'
import { useAzureSpeechStore } from '../stores/azureSpeechStore'
import { recognitionToTranslation } from '../config/azureSpeechConfig'

export function useAzureSpeech() {
  // Pinia ìŠ¤í† ì–´ (ì‹±ê¸€í†¤)
  const speechStore = useAzureSpeechStore()

  // ìƒíƒœ
  const isInitialized = ref(false)
  const isRecognizing = ref(false)
  const isConnecting = ref(false)
  const error = ref(null)

  // ì¸ì‹ ê²°ê³¼
  const partialText = ref('')
  const finalText = ref('')
  const partialTranslation = ref('')
  const finalTranslation = ref('')

  // ì¸ì‹ëœ ëª¨ë“  ë¬¸ì¥
  const recognizedSentences = ref([])
  const translatedSentences = ref([])

  // Azure SDK ì¸ìŠ¤í„´ìŠ¤
  let speechConfig = null
  let audioConfig = null
  let translationRecognizer = null

  // ì„¤ì •
  const fromLanguage = ref('ko-KR')
  const toLanguage = ref('en')

  // VAD ì„¤ì •
  const vadSilenceTimeout = ref(1000) // ms, ê¸°ë³¸ê°’ 1000ms

  // ì¸ì‹ë¥  í–¥ìƒì„ ìœ„í•œ êµ¬ë¬¸ ëª©ë¡
  const phraseList = ref([])

  /**
   * ë°±ì—”ë“œì—ì„œ í† í°ì„ ë°›ì•„ Azure Speech SDK ì´ˆê¸°í™”
   *
   * @param {string} sourceLang - ì›ë³¸ ì–¸ì–´ (BCP-47 í˜•ì‹, ì˜ˆ: 'ko-KR')
   * @param {string} targetLang - ëª©í‘œ ì–¸ì–´ (2ê¸€ì ISO ì½”ë“œ, ì˜ˆ: 'en')
   * @throws {Error} ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ
   */
  async function initialize(sourceLang, targetLang) {
    try {
      isConnecting.value = true
      error.value = null

      // ìŠ¤í† ì–´ì—ì„œ í† í° ê°€ì ¸ì˜¤ê¸° (ìºì‹± ì§€ì›)
      const { token, region } = await speechStore.ensureToken()

      // Speech ì„¤ì • ìƒì„±
      speechConfig = SpeechSDK.SpeechTranslationConfig.fromAuthorizationToken(token, region)

      // ì›ë³¸ ì–¸ì–´ ì„¤ì • (ì¸ì‹)
      speechConfig.speechRecognitionLanguage = sourceLang
      fromLanguage.value = sourceLang

      // ëª©í‘œ ì–¸ì–´ ì„¤ì • (ë²ˆì—­)
      speechConfig.addTargetLanguage(targetLang)
      toLanguage.value = targetLang

      // VAD ì„¤ì •
      // Speech_SegmentationSilenceTimeoutMs: ë°œí™” ì¢…ë£Œë¡œ ê°„ì£¼í•˜ê¸° ì „ ëŒ€ê¸° ì‹œê°„
      // ë‚®ì€ ê°’ (700ms): ë¹ ë¥¸ ì‘ë‹µ, ë°œí™”ê°€ ì˜ë¦´ ìˆ˜ ìˆìŒ
      // ë†’ì€ ê°’ (1500ms): ê¸´ ë¬¸ì¥ì— ìœ ë¦¬, ì‘ë‹µ ëŠë¦¼
      speechConfig.setProperty(
        SpeechSDK.PropertyId.Speech_SegmentationSilenceTimeoutMs,
        vadSilenceTimeout.value.toString()
      )

      // ìƒì„¸ ê²°ê³¼ í™œì„±í™”
      speechConfig.outputFormat = SpeechSDK.OutputFormat.Detailed

      // ê¸°ë³¸ ë§ˆì´í¬ì—ì„œ ì˜¤ë””ì˜¤ ì„¤ì • ìƒì„±
      audioConfig = SpeechSDK.AudioConfig.fromDefaultMicrophoneInput()

      // ë²ˆì—­ ì¸ì‹ê¸° ìƒì„±
      translationRecognizer = new SpeechSDK.TranslationRecognizer(speechConfig, audioConfig)

      // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
      setupEventHandlers()

      // êµ¬ë¬¸ ëª©ë¡ì´ ìˆìœ¼ë©´ ì ìš©
      if (phraseList.value.length > 0) {
        applyPhraseList()
      }

      isInitialized.value = true
      isConnecting.value = false

      console.log('âœ… Azure Speech SDK initialized successfully')
      console.log(`   Source: ${sourceLang}, Target: ${targetLang}`)
    } catch (err) {
      console.error('âŒ Failed to initialize Azure Speech SDK:', err)
      error.value = err.message
      isConnecting.value = false
      throw err
    }
  }

  /**
   * ë²ˆì—­ ì¸ì‹ê¸°ì˜ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
   */
  function setupEventHandlers() {
    if (!translationRecognizer) return

    // ì¸ì‹ ì¤‘ (ë¶€ë¶„ ê²°ê³¼)
    translationRecognizer.recognizing = (s, e) => {
      if (e.result.reason === SpeechSDK.ResultReason.TranslatingSpeech) {
        // ì›ë³¸ í…ìŠ¤íŠ¸ (ë¶€ë¶„)
        partialText.value = e.result.text

        // ë²ˆì—­ëœ í…ìŠ¤íŠ¸ (ë¶€ë¶„)
        const translations = e.result.translations
        if (translations.get(toLanguage.value)) {
          partialTranslation.value = translations.get(toLanguage.value)
        }

        console.log(`ğŸ¤ Recognizing: "${e.result.text}"`)
        console.log(`ğŸŒ Translating: "${partialTranslation.value}"`)
      }
    }

    // ì¸ì‹ ì™„ë£Œ (ìµœì¢… ê²°ê³¼)
    translationRecognizer.recognized = (s, e) => {
      if (e.result.reason === SpeechSDK.ResultReason.TranslatedSpeech) {
        const originalText = e.result.text
        const translations = e.result.translations
        const translatedText = translations.get(toLanguage.value) || ''

        if (originalText && originalText.trim()) {
          // ìµœì¢… í…ìŠ¤íŠ¸ì— ì¶”ê°€
          finalText.value += (finalText.value ? ' ' : '') + originalText
          finalTranslation.value += (finalTranslation.value ? ' ' : '') + translatedText

          // ë¬¸ì¥ ë°°ì—´ì— ì¶”ê°€
          recognizedSentences.value.push({
            text: originalText,
            timestamp: new Date().toISOString(),
            confidence: e.result.properties.getProperty(
              SpeechSDK.PropertyId.SpeechServiceResponse_JsonResult
            )
          })

          translatedSentences.value.push({
            text: translatedText,
            timestamp: new Date().toISOString()
          })

          console.log(`âœ… Recognized: "${originalText}"`)
          console.log(`âœ… Translated: "${translatedText}"`)
        }

        // ë¶€ë¶„ ê²°ê³¼ ì´ˆê¸°í™”
        partialText.value = ''
        partialTranslation.value = ''
      } else if (e.result.reason === SpeechSDK.ResultReason.NoMatch) {
        console.log('âš ï¸ No speech could be recognized')
      }
    }

    // ì·¨ì†Œë¨ (ì—ëŸ¬ ì²˜ë¦¬)
    translationRecognizer.canceled = (s, e) => {
      console.error('âŒ Recognition canceled:', e.errorDetails)

      if (e.reason === SpeechSDK.CancellationReason.Error) {
        error.value = e.errorDetails

        // í† í° ë§Œë£Œ ì²˜ë¦¬
        if (e.errorDetails.includes('authentication') || e.errorDetails.includes('token')) {
          console.log('ğŸ”„ Token expired, need to reinitialize')
        }
      }

      stopRecognition()
    }

    // ì„¸ì…˜ ì‹œì‘ë¨
    translationRecognizer.sessionStarted = (s, e) => {
      console.log('ğŸ™ï¸ Speech recognition session started')
    }

    // ì„¸ì…˜ ì¤‘ì§€ë¨
    translationRecognizer.sessionStopped = (s, e) => {
      console.log('â¹ï¸ Speech recognition session stopped')
      isRecognizing.value = false
    }
  }

  /**
   * íŠ¹ì • ìš©ì–´ ì¸ì‹ë¥  í–¥ìƒì„ ìœ„í•œ êµ¬ë¬¸ ëª©ë¡ ì ìš©
   */
  function applyPhraseList() {
    if (!translationRecognizer || phraseList.value.length === 0) return

    const grammar = SpeechSDK.PhraseListGrammar.fromRecognizer(translationRecognizer)

    phraseList.value.forEach(phrase => {
      grammar.addPhrase(phrase)
    })

    console.log(`ğŸ“ Applied ${phraseList.value.length} phrases to recognition`)
  }

  /**
   * ì—°ì† ìŒì„± ì¸ì‹ ë° ë²ˆì—­ ì‹œì‘
   */
  async function startRecognition() {
    if (!isInitialized.value) {
      throw new Error('Speech SDK not initialized. Call initialize() first.')
    }

    if (isRecognizing.value) {
      console.warn('âš ï¸ Recognition already running')
      return
    }

    try {
      error.value = null
      isRecognizing.value = true

      await translationRecognizer.startContinuousRecognitionAsync()

      console.log('â–¶ï¸ Started continuous recognition')
    } catch (err) {
      console.error('âŒ Failed to start recognition:', err)
      error.value = err.message
      isRecognizing.value = false
      throw err
    }
  }

  /**
   * ì—°ì† ìŒì„± ì¸ì‹ ì¤‘ì§€
   */
  async function stopRecognition() {
    if (!isRecognizing.value) {
      return
    }

    try {
      await translationRecognizer.stopContinuousRecognitionAsync()

      isRecognizing.value = false

      console.log('â¹ï¸ Stopped continuous recognition')
    } catch (err) {
      console.error('âŒ Failed to stop recognition:', err)
      throw err
    }
  }

  /**
   * VAD ë¬´ìŒ íƒ€ì„ì•„ì›ƒ ì—…ë°ì´íŠ¸
   *
   * @param {number} timeoutMs - ë¬´ìŒ íƒ€ì„ì•„ì›ƒ(ë°€ë¦¬ì´ˆ) (700-1500 ê¶Œì¥)
   */
  function updateVADSettings(timeoutMs) {
    vadSilenceTimeout.value = timeoutMs

    if (speechConfig) {
      speechConfig.setProperty(
        SpeechSDK.PropertyId.Speech_SegmentationSilenceTimeoutMs,
        timeoutMs.toString()
      )

      console.log(`âš™ï¸ Updated VAD silence timeout to ${timeoutMs}ms`)
    }
  }

  /**
   * ì¸ì‹ë¥  í–¥ìƒì„ ìœ„í•œ êµ¬ë¬¸ ì¶”ê°€
   *
   * @param {string[]} phrases - êµ¬ë¬¸ ë°°ì—´
   */
  function addPhrases(phrases) {
    phraseList.value = [...phraseList.value, ...phrases]

    if (translationRecognizer) {
      applyPhraseList()
    }
  }

  /**
   * êµ¬ë¬¸ ëª©ë¡ ì´ˆê¸°í™”
   */
  function clearPhrases() {
    phraseList.value = []
  }

  /**
   * ëª¨ë“  ì¸ì‹ ê²°ê³¼ ì´ˆê¸°í™”
   */
  function clearResults() {
    partialText.value = ''
    finalText.value = ''
    partialTranslation.value = ''
    finalTranslation.value = ''
    recognizedSentences.value = []
    translatedSentences.value = []
  }

  /**
   * ëª¨ë“  ë¦¬ì†ŒìŠ¤ ì •ë¦¬
   */
  function dispose() {
    if (translationRecognizer) {
      translationRecognizer.close()
      translationRecognizer = null
    }

    speechConfig = null
    audioConfig = null
    isInitialized.value = false
    isRecognizing.value = false

    console.log('ğŸ—‘ï¸ Azure Speech SDK disposed')
  }

  // ê³„ì‚°ëœ ê°’
  const fullOriginalText = computed(() => {
    return finalText.value + (partialText.value ? ' ' + partialText.value : '')
  })

  const fullTranslatedText = computed(() => {
    return finalTranslation.value + (partialTranslation.value ? ' ' + partialTranslation.value : '')
  })

  const recognizedCount = computed(() => recognizedSentences.value.length)

  return {
    // ìƒíƒœ
    isInitialized,
    isRecognizing,
    isConnecting,
    error,

    // ê²°ê³¼
    partialText,
    finalText,
    partialTranslation,
    finalTranslation,
    recognizedSentences,
    translatedSentences,
    fullOriginalText,
    fullTranslatedText,
    recognizedCount,

    // ì„¤ì •
    fromLanguage,
    toLanguage,
    vadSilenceTimeout,
    phraseList,

    // ë©”ì„œë“œ
    initialize,
    startRecognition,
    stopRecognition,
    updateVADSettings,
    addPhrases,
    clearPhrases,
    clearResults,
    dispose
  }
}
