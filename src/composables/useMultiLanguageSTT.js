/**
 * Multi-language STT Composable
 *
 * ë‹¤êµ­ì–´ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ë° ë²ˆì—­ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” Composable
 *
 * ì£¼ìš” ê¸°ëŠ¥:
 * - ì—¬ëŸ¬ ì–¸ì–´ ì„ íƒ ì§€ì›
 * - ìë™ ì–¸ì–´ ê°ì§€ (Azure STT)
 * - ì‹¤ì‹œê°„ ë‹¤êµ­ì–´ ë²ˆì—­
 * - WebSocket ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë°
 * - ë²ˆì—­ ê²°ê³¼ ì¹´ë“œ ìë™ ìƒì„±
 *
 * @example
 * import { useMultiLanguageSTT } from '@/composables/useMultiLanguageSTT'
 *
 * const {
 *   isRecording,
 *   translationCards,
 *   startRecording,
 *   stopRecording,
 *   clearCards
 * } = useMultiLanguageSTT()
 *
 * // ë…¹ìŒ ì‹œì‘ (ì„ íƒëœ ì–¸ì–´ ì „ë‹¬)
 * await startRecording(['ko-KR', 'en-US', 'ja-JP'])
 */
import { ref, onUnmounted } from 'vue'
import { createMultiLangSTTStream } from '../services/voiceService'

export function useMultiLanguageSTT() {
  // ìƒíƒœ ê´€ë¦¬
  const isRecording = ref(false)
  const isConnected = ref(false)
  const error = ref(null)

  // ë²ˆì—­ ì¹´ë“œ ëª©ë¡ (ìµœì‹  ì¹´ë“œê°€ ë§¨ ì•)
  const translationCards = ref([])

  // ì¤‘ê°„ ì¸ì‹ ê²°ê³¼ (ì‹¤ì‹œê°„ í‘œì‹œìš©)
  const recognizingText = ref('')

  // WebSocket ë° MediaRecorder ì¸ìŠ¤í„´ìŠ¤
  let wsConnection = null
  let mediaRecorder = null
  let audioStream = null

  /**
   * ë…¹ìŒ ì‹œì‘ (ë§ˆì´í¬ ì…ë ¥ + WebSocket ì—°ê²°)
   *
   * @param {string[]} selectedLanguages - ì„ íƒëœ ì–¸ì–´ ëª©ë¡ (BCP-47 ì½”ë“œ)
   * @returns {Promise<void>}
   */
  async function startRecording(selectedLanguages = ['ko-KR', 'en-US']) {
    try {
      error.value = null

      // ì–¸ì–´ê°€ 2ê°œ ë¯¸ë§Œì´ë©´ ì—ëŸ¬
      if (!selectedLanguages || selectedLanguages.length < 2) {
        throw new Error('ìµœì†Œ 2ê°œ ì´ìƒì˜ ì–¸ì–´ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.')
      }

      // 1. ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ë° ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ íšë“
      console.log('ğŸ¤ Requesting microphone access...')
      audioStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,      // Azure STT ê¶Œì¥: 16kHz
          channelCount: 1,        // ëª¨ë…¸
          echoCancellation: true, // ì—ì½” ì œê±°
          noiseSuppression: true  // ë…¸ì´ì¦ˆ ê°ì†Œ
        }
      })

      console.log('âœ… Microphone access granted')

      // 2. MediaRecorder ë¨¼ì € ìƒì„± (ì•„ì§ ì‹œì‘í•˜ì§€ ì•ŠìŒ)
      const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus')
        ? 'audio/webm;codecs=opus'
        : 'audio/webm'

      mediaRecorder = new MediaRecorder(audioStream, {
        mimeType,
        audioBitsPerSecond: 16000 // 16kbps
      })

      // ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹  ì‹œ WebSocketìœ¼ë¡œ ì „ì†¡
      mediaRecorder.ondataavailable = (event) => {
        // â˜… WebSocket readyState ëª…ì‹œì  í™•ì¸ (OPEN = 1)
        if (event.data.size > 0 && wsConnection && wsConnection.ws.readyState === WebSocket.OPEN) {
          console.log('ğŸ“¤ Sending audio chunk:', event.data.size, 'bytes')
          wsConnection.send(event.data)
        } else if (event.data.size > 0 && wsConnection) {
          console.warn('âš ï¸ Dropping audio chunk, WebSocket not ready. ReadyState:', wsConnection.ws.readyState)
        }
      }

      // 3. WebSocket ì—°ê²° ìƒì„± (ë‹¤êµ­ì–´ ëª¨ë“œ)
      console.log('ğŸ”Œ Connecting to Multi-lang WebSocket STT...')
      wsConnection = createMultiLangSTTStream(selectedLanguages, {
        onConnected: () => {
          // â˜… WebSocket ì—°ê²° ì™„ë£Œ í›„ MediaRecorder ì‹œì‘
          console.log('ğŸ”— WebSocket connected, waiting for stability...')

          // 200ms ëŒ€ê¸° í›„ MediaRecorder ì‹œì‘ (WebSocket ì™„ì „íˆ ì•ˆì •í™”)
          setTimeout(() => {
            if (mediaRecorder && mediaRecorder.state === 'inactive') {
              // WebSocket readyState ì¬í™•ì¸
              if (wsConnection && wsConnection.ws.readyState === WebSocket.OPEN) {
                mediaRecorder.start(100) // 100msë§ˆë‹¤ ì²­í¬ ì „ì†¡
                isRecording.value = true
                isConnected.value = true
                console.log('ğŸ”´ Multi-lang recording started')
                console.log('Selected languages:', selectedLanguages)
                console.log('WebSocket readyState:', wsConnection.ws.readyState)
              } else {
                console.error('âŒ WebSocket not OPEN after delay. ReadyState:', wsConnection?.ws?.readyState)
                error.value = 'WebSocket ì—°ê²°ì´ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤'
              }
            }
          }, 200)
        },

        onRecognizing: (message) => {
          // ì¤‘ê°„ ì¸ì‹ ê²°ê³¼ (ë²ˆì—­ ì—†ìŒ)
          recognizingText.value = message.text || ''
        },

        onRecognized: (message) => {
          // ìµœì¢… ì¸ì‹ ê²°ê³¼ + ë²ˆì—­
          console.log('âœ… Recognized:', message)

          // ì¤‘ê°„ ê²°ê³¼ ì´ˆê¸°í™”
          recognizingText.value = ''

          // ë²ˆì—­ ì¹´ë“œ ì¶”ê°€ (ìµœì‹  ì¹´ë“œê°€ ë§¨ ì•ìœ¼ë¡œ)
          if (message.text && message.text.trim()) {
            translationCards.value.unshift({
              id: Date.now(), // ê³ ìœ  ID
              original: message.text,
              detectedLang: message.detected_language || 'ko-KR',
              translations: message.translations || [],
              timestamp: new Date().toISOString()
            })

            // ìµœëŒ€ 50ê°œ ì¹´ë“œë§Œ ìœ ì§€ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
            if (translationCards.value.length > 50) {
              translationCards.value = translationCards.value.slice(0, 50)
            }
          }
        },

        onError: (errorMessage) => {
          console.error('âŒ Multi-lang STT error:', errorMessage)
          error.value = errorMessage
        },

        onEnd: () => {
          isConnected.value = false
          console.log('ğŸ”š Multi-lang STT stream ended')
        }
      })

    } catch (err) {
      console.error('âŒ Failed to start multi-lang recording:', err)
      error.value = err.message || 'ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨'

      // ì—ëŸ¬ ë°œìƒ ì‹œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
      cleanup()

      throw err
    }
  }

  /**
   * ë…¹ìŒ ì¤‘ì§€ (ë§ˆì´í¬ í•´ì œ + WebSocket ì¢…ë£Œ)
   */
  function stopRecording() {
    try {
      console.log('â¹ï¸ Stopping multi-lang recording...')

      // MediaRecorder ì¤‘ì§€
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop()
        console.log('â¹ï¸ MediaRecorder stopped')
      }

      // ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ í•´ì œ
      if (audioStream) {
        audioStream.getTracks().forEach(track => track.stop())
        console.log('ğŸ”‡ Audio stream released')
      }

      // WebSocket ì—°ê²° ì¢…ë£Œ
      if (wsConnection) {
        wsConnection.close()
        console.log('ğŸ”Œ WebSocket closed')
      }

      isRecording.value = false
      isConnected.value = false
      recognizingText.value = ''

      console.log('âœ… Multi-lang recording stopped')

    } catch (err) {
      console.error('âŒ Failed to stop recording:', err)
      error.value = err.message || 'ë…¹ìŒ ì¤‘ì§€ ì‹¤íŒ¨'
    }
  }

  /**
   * ë²ˆì—­ ì¹´ë“œ ëª©ë¡ ì´ˆê¸°í™”
   */
  function clearCards() {
    translationCards.value = []
    console.log('ğŸ—‘ï¸ Translation cards cleared')
  }

  /**
   * ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ)
   */
  function cleanup() {
    if (isRecording.value) {
      stopRecording()
    }

    // ëª¨ë“  ì°¸ì¡° í•´ì œ
    wsConnection = null
    mediaRecorder = null
    audioStream = null
  }

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ìë™ ì •ë¦¬
  onUnmounted(() => {
    cleanup()
  })

  return {
    // ìƒíƒœ
    isRecording,
    isConnected,
    error,

    // ë°ì´í„°
    translationCards,
    recognizingText,

    // ë©”ì„œë“œ
    startRecording,
    stopRecording,
    clearCards
  }
}
