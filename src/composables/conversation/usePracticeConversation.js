/**
 * Practice ëŒ€í™” ê´€ë¦¬ Composable
 *
 * íšŒí™” ì—°ìŠµ í˜ì´ì§€ì˜ ë©”ì‹œì§€ ê´€ë¦¬ ë° ëŒ€í™” ë¡œì§ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
 * - ë©”ì‹œì§€ ì†¡ìˆ˜ì‹ 
 * - ë²ˆì—­ ê¸°ëŠ¥
 * - ìš©ì–´ íƒì§€
 * - ëŒ€í™” ì´ˆê¸°í™”
 *
 * @module usePracticeConversation
 */
import { ref, computed, nextTick } from 'vue'
import conversationService from '@/services/conversationService'

/**
 * Blobì„ Base64 ë¬¸ìì—´ë¡œ ë³€í™˜
 *
 * @param {Blob} blob - ë³€í™˜í•  Blob
 * @returns {Promise<string>} Base64 ë¬¸ìì—´
 */
async function blobToBase64(blob) {
  return new Promise((resolve, reject) => {
    const reader = new FileReader()
    reader.onloadend = () => {
      const base64 = reader.result.split(',')[1]
      resolve(base64)
    }
    reader.onerror = reject
    reader.readAsDataURL(blob)
  })
}

/**
 * Practice ëŒ€í™” ë¡œì§
 *
 * @param {Object} options - ì˜µì…˜
 * @param {Ref<Object>} options.scenario - ì‹œë‚˜ë¦¬ì˜¤ ref
 * @param {Function} options.onFeedbackReceived - í”¼ë“œë°± ìˆ˜ì‹  ì½œë°±
 * @param {Function} options.getAudioBlob - ì˜¤ë””ì˜¤ blob ê°€ì ¸ì˜¤ê¸° ì½œë°± (ìŒì„± ëª¨ë“œì—ì„œ ë°œìŒ í‰ê°€ìš©)
 * @param {Ref<string>} options.userInput - ì™¸ë¶€ì—ì„œ ì „ë‹¬ë°›ì€ userInput ref (ì„ íƒ)
 * @returns {Object} ëŒ€í™” ìƒíƒœ ë° ë©”ì„œë“œ
 */
export function usePracticeConversation({ scenario, onFeedbackReceived, getAudioBlob, userInput: externalUserInput }) {
  // ============================================
  // State
  // ============================================
  const messages = ref([])
  const detectedTerms = ref([])
  // ì™¸ë¶€ì—ì„œ userInputì´ ì „ë‹¬ë˜ë©´ ê·¸ê²ƒì„ ì‚¬ìš©, ì•„ë‹ˆë©´ ë‚´ë¶€ì—ì„œ ìƒì„±
  const userInput = externalUserInput || ref('')
  const isLoading = ref(false)
  const translationLoading = ref({})
  const hintLoading = ref({}) // Added
  const conversationArea = ref(null)

  // ============================================
  // Computed
  // ============================================

  /**
   * ì‚¬ìš©ì ë©”ì‹œì§€ë§Œ í•„í„°ë§
   */
  const userMessages = computed(() =>
    messages.value.filter(msg => msg.speaker === 'user')
  )

  /**
   * ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ í•„ìˆ˜ ìš©ì–´ ì¶”ì¶œ
   */
  const requiredTerms = computed(() => {
    return scenario.value?.requiredTerms || []
  })

  /**
   * ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ (Avatar TTSìš©)
   */
  const lastAiMessage = computed(() => {
    const aiMessages = messages.value.filter(m => m.speaker === 'ai')
    return aiMessages.length > 0 ? aiMessages[aiMessages.length - 1].message : ''
  })

  // ============================================
  // Actions
  // ============================================

  /**
   * ë©”ì‹œì§€ ì „ì†¡
   *
   * @param {string} scenarioId - ì‹œë‚˜ë¦¬ì˜¤ ID
   * @returns {Promise<void>}
   */
  const sendMessage = async (scenarioId) => {
    if (!userInput.value.trim() || isLoading.value) return

    const message = userInput.value.trim()
    userInput.value = ''

    try {
      isLoading.value = true

      // ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
      messages.value.push({
        speaker: 'user',
        message,
        timestamp: new Date()
      })

      await nextTick()
      scrollToBottom()

      // ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
      const history = messages.value.slice(0, -1).map(msg => ({
        speaker: msg.speaker,
        message: msg.message
      }))

      // API í˜¸ì¶œ
      const response = await conversationService.sendMessage(scenarioId, message, history)

      // ìš©ì–´ íƒì§€ ì—…ë°ì´íŠ¸
      if (response.detectedTerms?.length) {
        detectedTerms.value = [...new Set([...detectedTerms.value, ...response.detectedTerms])]
      }

      // AI ì‘ë‹µ ì¶”ê°€
      messages.value.push({
        speaker: 'ai',
        message: response.aiMessage,
        timestamp: new Date()
      })

      isLoading.value = false
      await nextTick()
      scrollToBottom()

      // í”¼ë“œë°± ìš”ì²­ (ìŒì„± ëª¨ë“œì¼ ê²½ìš° ì˜¤ë””ì˜¤ ë°ì´í„° í¬í•¨)
      try {
        let audioData = null

        // ì˜¤ë””ì˜¤ blobì´ ìˆìœ¼ë©´ Base64ë¡œ ë³€í™˜
        if (getAudioBlob) {
          const audioBlob = getAudioBlob()
          if (audioBlob) {
            try {
              audioData = await blobToBase64(audioBlob)
              console.log('ğŸ¤ Audio data prepared for pronunciation assessment:', audioData.length, 'chars')
            } catch (audioErr) {
              console.warn('Failed to convert audio to Base64:', audioErr)
            }
          }
        }

        const feedbackResponse = await conversationService.getFeedback(
          scenarioId,
          message,
          response.detectedTerms || [],
          audioData
        )

        if (onFeedbackReceived) {
          onFeedbackReceived(feedbackResponse.feedback)
        }
      } catch (e) {
        console.error('Feedback request failed:', e)
        // í”¼ë“œë°± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í”¼ë“œë°±
        if (onFeedbackReceived) {
          onFeedbackReceived({
            score: 7,
            grammar_corrections: [],
            terminology_usage: { used: [], missed: [], feedback: 'í”¼ë“œë°±ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.' },
            suggestions: ['ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'],
            score_breakdown: { grammar: 7, vocabulary: 7, fluency: 7 }
          })
        }
      }
    } catch (err) {
      console.error('Send message error:', err)
      messages.value.pop()
      isLoading.value = false
      throw err
    }
  }

  /**
   * ë²ˆì—­ í† ê¸€
   *
   * @param {number} index - ë©”ì‹œì§€ ì¸ë±ìŠ¤
   */
  const toggleTranslation = async (index) => {
    const msg = messages.value[index]

    if (msg.showTranslation) {
      msg.showTranslation = false
      return
    }

    if (msg.translatedText) {
      msg.showTranslation = true
      return
    }

    translationLoading.value[index] = true

    try {
      const response = await conversationService.translateMessage(msg.message, 'ko')
      msg.translatedText = response.translatedText
      msg.showTranslation = true
    } catch (err) {
      console.error('Translation failed:', err)
      msg.translatedText = '[ë²ˆì—­ ì‹¤íŒ¨] ' + msg.message
      msg.showTranslation = true
    } finally {
      translationLoading.value[index] = false
    }
  }

  /**
   * íŒíŠ¸ í† ê¸€
   * ì‹œë‚˜ë¦¬ì˜¤ ë§¥ë½ê³¼ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§¥ë½ì— ë§ëŠ” íŒíŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
   *
   * @param {number} index - ë©”ì‹œì§€ ì¸ë±ìŠ¤
   * @param {string} scenarioId - ì‹œë‚˜ë¦¬ì˜¤ ID
   */
  const toggleHint = async (index, scenarioId) => {
    const msg = messages.value[index]

    if (msg.showHint) {
      msg.showHint = false
      return
    }

    // ì´ë¯¸ ìƒì„±ëœ íŒíŠ¸ê°€ ìˆìœ¼ë©´ ì¬ì‚¬ìš©
    if (msg.hints && msg.hints.length > 0) {
      msg.showHint = true
      return
    }

    hintLoading.value[index] = true

    try {
      // ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„± (í˜„ì¬ ë©”ì‹œì§€ê¹Œì§€)
      const history = messages.value.slice(0, index + 1).map(m => ({
        speaker: m.speaker,
        message: m.message
      }))

      // ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ ì°¾ê¸°
      const lastAiMessage = msg.speaker === 'ai' ? msg.message : ''

      // API í˜¸ì¶œ
      const response = await conversationService.getHint(
        scenarioId,
        history,
        lastAiMessage,
        3  // íŒíŠ¸ 3ê°œ ìƒì„±
      )

      if (response.success) {
        // íŒíŠ¸ ì •ë³´ ì €ì¥
        msg.hints = response.hints || []
        msg.hintExplanations = response.hint_explanations || []
        msg.terminologySuggestions = response.terminology_suggestions || []
        msg.showHint = true
      } else {
        console.error('Hint generation failed:', response)
        msg.hints = ['I see what you mean.', 'Could you tell me more?', 'That\'s interesting.']
        msg.showHint = true
      }
    } catch (err) {
      console.error('Hint generation failed:', err)
      // ì—ëŸ¬ ì‹œ ê¸°ë³¸ íŒíŠ¸ ì œê³µ
      msg.hints = ['I understand.', 'Please continue.', 'That makes sense.']
      msg.showHint = true
    } finally {
      hintLoading.value[index] = false
    }
  }

  /**
   * ëŒ€í™” ìƒíƒœ ì´ˆê¸°í™” (í”„ë¡ íŠ¸ì—”ë“œë§Œ)
   * ë°±ì—”ë“œ ì„¸ì…˜ ì‚­ì œëŠ” í˜¸ì¶œí•˜ëŠ” ìª½ì—ì„œ ë³„ë„ë¡œ ì²˜ë¦¬í•´ì•¼ í•¨
   *
   * @returns {void}
   */
  const resetConversation = () => {
    messages.value = []
    detectedTerms.value = []
  }

  /**
   * íˆìŠ¤í† ë¦¬ ë°ì´í„° ë¡œë“œ
   *
   * @param {Object} historyResponse - íˆìŠ¤í† ë¦¬ ì‘ë‹µ
   */
  const loadHistory = (historyResponse) => {
    messages.value = historyResponse.messages.map(msg => ({
      speaker: msg.sender,
      message: msg.message,
      translatedText: msg.translatedText,
      timestamp: new Date(msg.createdAt),
      showTranslation: false
    }))

    historyResponse.messages.forEach(msg => {
      if (msg.detectedTerms?.length > 0) {
        detectedTerms.value = [...new Set([...detectedTerms.value, ...msg.detectedTerms])]
      }
    })
  }

  /**
   * ì´ˆê¸° AI ë©”ì‹œì§€ ì¶”ê°€
   *
   * @param {string} initialMessage - ì´ˆê¸° ë©”ì‹œì§€
   */
  const addInitialMessage = (initialMessage) => {
    if (initialMessage) {
      messages.value.push({
        speaker: 'ai',
        message: initialMessage,
        timestamp: new Date()
      })
    }
  }

  /**
   * ìŠ¤í¬ë¡¤ì„ ë§¨ ì•„ë˜ë¡œ ì´ë™
   */
  const scrollToBottom = () => {
    if (conversationArea.value) {
      conversationArea.value.scrollTop = conversationArea.value.scrollHeight
    }
  }

  /**
   * ì‹œê°„ í¬ë§·íŒ…
   *
   * @param {Date} date - ë‚ ì§œ
   * @returns {string} í¬ë§·ëœ ì‹œê°„
   */
  const formatTime = (date) => {
    return new Date(date).toLocaleTimeString([], {
      hour: '2-digit',
      minute: '2-digit'
    })
  }

  // ============================================
  // Return
  // ============================================
  return {
    // State
    messages,
    detectedTerms,
    userInput,
    isLoading,
    translationLoading,
    hintLoading, // Added
    conversationArea,

    // Computed
    userMessages,
    requiredTerms,
    lastAiMessage,

    // Actions
    sendMessage,
    toggleTranslation,
    toggleHint, // Added
    resetConversation,
    loadHistory,
    addInitialMessage,
    scrollToBottom,
    formatTime
  }
}
