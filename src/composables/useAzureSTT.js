/**
 * Azure Speech STT Composable (ê³µì‹ Azure Speech SDK ì‚¬ìš©)
 *
 * ë¸Œë¼ìš°ì € SDK ê¸°ë°˜ êµ¬ì¡°:
 * - Frontend: Azure Speech SDKë¡œ ì§ì ‘ STT ìˆ˜í–‰ (ë§ˆì´í¬ â†’ Azure)
 * - Backend: ë²ˆì—­ë§Œ ë‹´ë‹¹ (TranslationAgent)
 *
 * ì˜¤ë””ì˜¤ ì²˜ë¦¬:
 * - Azure Speech SDKê°€ ìë™ìœ¼ë¡œ ë§ˆì´í¬ ì…ë ¥ ì²˜ë¦¬ (WebSocket ë‚´ì¥)
 * - AudioConfig.fromDefaultMicrophoneInput() ì‚¬ìš©
 *
 * ì¸ì¦:
 * - Backendì—ì„œ ì„ì‹œ í† í° ë°œê¸‰ (/api/ai/speech/token)
 * - Subscription Key ë…¸ì¶œ ë°©ì§€
 *
 * ë‹¤êµ­ì–´ ì§€ì›:
 * - AutoDetectSourceLanguageConfigë¡œ ìë™ ì–¸ì–´ ê°ì§€
 * - ì¸ì‹ëœ ì–¸ì–´ë¡œë¶€í„° ë‹¤ë¥¸ ì–¸ì–´ë¡œ ë²ˆì—­ (Backend Agent)
 *
 * @example
 * import { useAzureSTT } from '@/composables/useAzureSTT'
 *
 * const {
 *   isRecording,
 *   translationCards,
 *   startRecording,
 *   stopRecording
 * } = useAzureSTT()
 *
 * // ë‹¤êµ­ì–´ STT + ë²ˆì—­ ì‹œì‘
 * await startRecording(['ko-KR', 'en-US', 'ja-JP', 'vi-VN'])
 */
import { ref, onUnmounted } from 'vue'
import * as SpeechSDK from 'microsoft-cognitiveservices-speech-sdk'
import { pythonAPI } from '@/services/api'

export function useAzureSTT() {
  // ìƒíƒœ
  const isRecording = ref(false)
  const isConnected = ref(false)
  const error = ref(null)

  // ë²ˆì—­ ì¹´ë“œ ëª©ë¡
  const translationCards = ref([])
  const recognizingText = ref('')

  // Azure Speech SDK ì¸ìŠ¤í„´ìŠ¤
  let recognizer = null

  /**
   * ë…¹ìŒ ì‹œì‘ (Azure Speech SDK ì‚¬ìš©)
   *
   * @param {string[]} selectedLanguages - ì„ íƒëœ ì–¸ì–´ ëª©ë¡ (BCP-47)
   *   ì˜ˆ: ['ko-KR', 'en-US', 'ja-JP', 'vi-VN']
   */
  async function startRecording(selectedLanguages = ['ko-KR', 'en-US']) {
    try {
      error.value = null

      // ì–¸ì–´ ê²€ì¦
      if (!selectedLanguages || selectedLanguages.length < 2) {
        throw new Error('ìµœì†Œ 2ê°œ ì´ìƒì˜ ì–¸ì–´ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤')
      }

      console.log('ğŸ¤ Starting Azure Speech SDK recognition...')
      console.log('ğŸ“‹ Selected languages:', selectedLanguages)

      // 1. ë°±ì—”ë“œì—ì„œ ì„ì‹œ í† í° ë°œê¸‰
      const tokenResponse = await pythonAPI.get('/speech/token')
      const { token, region } = tokenResponse.data.data

      console.log('âœ… Token received from backend')
      console.log('ğŸŒ Region:', region)

      // 2. SpeechConfig ìƒì„± (í† í° ì¸ì¦)
      const speechConfig = SpeechSDK.SpeechConfig.fromAuthorizationToken(token, region)
      speechConfig.speechRecognitionLanguage = selectedLanguages[0] // ê¸°ë³¸ ì–¸ì–´

      // 3. AutoDetectSourceLanguageConfig ìƒì„± (ë‹¤êµ­ì–´ ìë™ ê°ì§€)
      const autoDetectConfig = SpeechSDK.AutoDetectSourceLanguageConfig.fromLanguages(
        selectedLanguages
      )

      // 4. AudioConfig ìƒì„± (ê¸°ë³¸ ë§ˆì´í¬)
      const audioConfig = SpeechSDK.AudioConfig.fromDefaultMicrophoneInput()

      // 5. SpeechRecognizer ìƒì„±
      recognizer = SpeechSDK.SpeechRecognizer.FromConfig(
        speechConfig,
        autoDetectConfig,
        audioConfig
      )

      console.log('ğŸ”§ SpeechRecognizer created')

      // 6. ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •

      // ì¤‘ê°„ ì¸ì‹ ê²°ê³¼ (ì‹¤ì‹œê°„)
      recognizer.recognizing = (sender, event) => {
        if (event.result.reason === SpeechSDK.ResultReason.RecognizingSpeech) {
          recognizingText.value = event.result.text
          console.log('ğŸ” Recognizing:', event.result.text)
        }
      }

      // ìµœì¢… ì¸ì‹ ê²°ê³¼
      recognizer.recognized = async (sender, event) => {
        if (event.result.reason === SpeechSDK.ResultReason.RecognizedSpeech) {
          const recognizedText = event.result.text
          const detectedLanguage = event.result.language || selectedLanguages[0]

          console.log('âœ… Recognized:', recognizedText)
          console.log('ğŸŒ Detected language:', detectedLanguage)

          recognizingText.value = ''

          if (recognizedText && recognizedText.trim()) {
            // ë°±ì—”ë“œë¡œ ë²ˆì—­ ìš”ì²­ (ì¸ì‹ëœ ì–¸ì–´ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì–¸ì–´ë¡œ ë²ˆì—­)
            try {
              const translations = await translateToMultipleLanguages(
                recognizedText,
                detectedLanguage,
                selectedLanguages
              )

              // ë²ˆì—­ ì¹´ë“œ ì¶”ê°€
              translationCards.value.unshift({
                id: Date.now(),
                original: recognizedText,
                detectedLang: detectedLanguage,
                translations: translations,
                timestamp: new Date().toISOString()
              })

              // ìµœëŒ€ 50ê°œ ì¹´ë“œë§Œ ìœ ì§€
              if (translationCards.value.length > 50) {
                translationCards.value = translationCards.value.slice(0, 50)
              }

              console.log('ğŸ“ Translation card added')
            } catch (err) {
              console.error('âŒ Translation failed:', err)
              error.value = 'ë²ˆì—­ ì‹¤íŒ¨: ' + err.message
            }
          }
        } else if (event.result.reason === SpeechSDK.ResultReason.NoMatch) {
          console.log('âš ï¸ No speech recognized')
        }
      }

      // ì¸ì‹ ì·¨ì†Œ/ì—ëŸ¬
      recognizer.canceled = (sender, event) => {
        console.log('âŒ Recognition canceled:', event.reason)

        if (event.reason === SpeechSDK.CancellationReason.Error) {
          console.error('âŒ Error details:', event.errorDetails)
          error.value = `ì¸ì‹ ì˜¤ë¥˜: ${event.errorDetails}`
        }

        stopRecording()
      }

      // ì„¸ì…˜ ì‹œì‘
      recognizer.sessionStarted = (sender, event) => {
        console.log('ğŸŸ¢ Session started')
        isConnected.value = true
      }

      // ì„¸ì…˜ ì¢…ë£Œ
      recognizer.sessionStopped = (sender, event) => {
        console.log('ğŸ”´ Session stopped')
        isConnected.value = false
      }

      // 7. ì—°ì† ì¸ì‹ ì‹œì‘
      recognizer.startContinuousRecognitionAsync(
        () => {
          console.log('ğŸ™ï¸ Continuous recognition started')
          isRecording.value = true
        },
        (err) => {
          console.error('âŒ Failed to start recognition:', err)
          error.value = 'ì¸ì‹ ì‹œì‘ ì‹¤íŒ¨: ' + err
          cleanup()
        }
      )
    } catch (err) {
      console.error('âŒ Failed to start recording:', err)
      error.value = err.message || 'ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨'
      cleanup()
      throw err
    }
  }

  /**
   * ë‹¤êµ­ì–´ ë²ˆì—­ (ë°±ì—”ë“œ TranslationAgent í˜¸ì¶œ)
   *
   * @param {string} text - ì¸ì‹ëœ ì›ë¬¸
   * @param {string} sourceLang - ê°ì§€ëœ ì–¸ì–´ (BCP-47: ko-KR, en-US ë“±)
   * @param {string[]} selectedLanguages - ì „ì²´ ì„ íƒ ì–¸ì–´ ëª©ë¡
   * @returns {Promise<Array>} ë²ˆì—­ ê²°ê³¼ ë°°ì—´
   */
  async function translateToMultipleLanguages(text, sourceLang, selectedLanguages) {
    // BCP-47 â†’ ISO 639-1 ë³€í™˜ (ko-KR â†’ ko, en-US â†’ en)
    const sourceIso = sourceLang.split('-')[0]

    // ì›ë³¸ ì–¸ì–´ ì œì™¸í•œ ëª©í‘œ ì–¸ì–´ ì¶”ì¶œ
    const targetLanguages = selectedLanguages
      .filter(lang => !lang.startsWith(sourceIso)) // ko-KRì´ë©´ koë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  ì–¸ì–´ ì œì™¸
      .map(lang => lang.split('-')[0]) // BCP-47 â†’ ISO 639-1

    if (targetLanguages.length === 0) {
      return []
    }

    console.log('ğŸ”„ Translating:', {
      text,
      from: sourceIso,
      to: targetLanguages
    })

    // ë°±ì—”ë“œ ë²ˆì—­ API í˜¸ì¶œ
    const response = await pythonAPI.post('/translate/multi', {
      text: text,
      source_lang: sourceIso,
      target_langs: targetLanguages
    })

    return response.data.translations || []
  }

  /**
   * ë…¹ìŒ ì¤‘ì§€
   */
  function stopRecording() {
    try {
      console.log('â¹ï¸ Stopping recording...')

      if (recognizer) {
        recognizer.stopContinuousRecognitionAsync(
          () => {
            console.log('âœ… Recognition stopped')
            cleanup()
          },
          (err) => {
            console.error('âŒ Failed to stop recognition:', err)
            cleanup()
          }
        )
      } else {
        cleanup()
      }
    } catch (err) {
      console.error('âŒ Failed to stop recording:', err)
      error.value = err.message || 'ë…¹ìŒ ì¤‘ì§€ ì‹¤íŒ¨'
      cleanup()
    }
  }

  /**
   * ë²ˆì—­ ì¹´ë“œ ì´ˆê¸°í™”
   */
  function clearCards() {
    translationCards.value = []
    console.log('ğŸ—‘ï¸ Translation cards cleared')
  }

  /**
   * ë¦¬ì†ŒìŠ¤ ì •ë¦¬
   */
  function cleanup() {
    if (recognizer) {
      recognizer.close()
      recognizer = null
    }

    isRecording.value = false
    isConnected.value = false
    recognizingText.value = ''
  }

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ìë™ ì •ë¦¬
  onUnmounted(() => {
    cleanup()
  })

  return {
    // ìƒíƒœ
    isRecording,
    isConnected,
    error,

    // ë°ì´í„°
    translationCards,
    recognizingText,

    // ë©”ì„œë“œ
    startRecording,
    stopRecording,
    clearCards
  }
}
