/**
 * Real-time STT Composable for Conversation Practice
 *
 * íšŒí™”ì—°ìŠµ í˜ì´ì§€ìš© ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ Composable
 * useMultiLanguageSTT.jsì˜ ì•„í‚¤í…ì²˜ë¥¼ ì¬ì‚¬ìš©í•˜ë˜, ë²ˆì—­ ì—†ì´ ë‹¨ì¼ ì–¸ì–´ STTì— ì§‘ì¤‘
 *
 * ì£¼ìš” ê¸°ëŠ¥:
 * - ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ (WebSocket ê¸°ë°˜)
 * - ì¤‘ê°„ ì¸ì‹ ê²°ê³¼ (recognizing) í‘œì‹œ
 * - ìµœì¢… ì¸ì‹ ê²°ê³¼ (recognized) ëˆ„ì 
 * - ë…¹ìŒ ì¤‘ì§€ ì‹œ ì „ì²´ í…ìŠ¤íŠ¸ ë°˜í™˜
 *
 * @see useMultiLanguageSTT.js - ê¸°ë°˜ ì•„í‚¤í…ì²˜
 * @see voice_realtime.py - ë°±ì—”ë“œ WebSocket API
 */
import { ref, computed, onUnmounted } from 'vue'
import { createMultiLangSTTStream } from '../services/voiceService'

export function useRealtimeSTT() {
  // ìƒíƒœ
  const isRecording = ref(false)
  const isConnected = ref(false)
  const isConnecting = ref(false)
  const error = ref(null)

  // ì¸ì‹ ê²°ê³¼
  const interimText = ref('')       // ì¤‘ê°„ ì¸ì‹ ê²°ê³¼ (recognizing)
  const finalTexts = ref([])        // ìµœì¢… ì¸ì‹ ê²°ê³¼ ë°°ì—´ (recognized)
  const recordingTime = ref(0)      // ë…¹ìŒ ì‹œê°„ (ì´ˆ)

  // ì˜¤ë””ì˜¤ ë…¹ìŒ (ë°œìŒ í‰ê°€ìš©)
  const audioBlob = ref(null)       // ë…¹ìŒëœ ì˜¤ë””ì˜¤ Blob

  // ë‚´ë¶€ ë¦¬ì†ŒìŠ¤
  let wsConnection = null
  let audioContext = null
  let audioWorkletNode = null
  let sourceNode = null
  let audioStream = null
  let recordingInterval = null
  let mediaRecorder = null          // MediaRecorder for audio capture
  let audioChunks = []              // ë…¹ìŒëœ ì˜¤ë””ì˜¤ ì²­í¬

  /**
   * ì „ì²´ ì¸ì‹ëœ í…ìŠ¤íŠ¸ (ìµœì¢… í…ìŠ¤íŠ¸ + ì¤‘ê°„ í…ìŠ¤íŠ¸)
   */
  const fullText = computed(() => {
    const finals = finalTexts.value.join(' ')
    const interim = interimText.value
    return interim ? `${finals} ${interim}`.trim() : finals
  })

  /**
   * ì‹¤ì‹œê°„ STT ë…¹ìŒ ì‹œì‘
   *
   * @param {string} language - ì¸ì‹ ì–¸ì–´ (BCP-47 ì½”ë“œ, ì˜ˆ: 'en-US')
   */
  async function startRecording(language = 'en-US') {
    if (isRecording.value || isConnecting.value) {
      console.warn('âš ï¸ Already recording or connecting')
      return
    }

    try {
      isConnecting.value = true
      error.value = null
      interimText.value = ''
      finalTexts.value = []
      recordingTime.value = 0
      audioBlob.value = null
      audioChunks = []

      // 1. ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
      audioStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 48000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        }
      })

      // 1.5 MediaRecorder ì„¤ì • (ë°œìŒ í‰ê°€ìš© ì˜¤ë””ì˜¤ ìº¡ì²˜)
      try {
        const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus')
          ? 'audio/webm;codecs=opus'
          : 'audio/webm'

        mediaRecorder = new MediaRecorder(audioStream, { mimeType })

        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            audioChunks.push(event.data)
          }
        }

        mediaRecorder.onstop = () => {
          if (audioChunks.length > 0) {
            audioBlob.value = new Blob(audioChunks, { type: 'audio/webm' })
            console.log('ğŸ¤ Audio captured:', audioBlob.value.size, 'bytes')
          }
        }

        mediaRecorder.start(100) // 100ms ê°„ê²©ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘
        console.log('ğŸ™ï¸ MediaRecorder started for pronunciation assessment')
      } catch (recorderErr) {
        console.warn('âš ï¸ MediaRecorder not available:', recorderErr)
        // MediaRecorder ì‹¤íŒ¨í•´ë„ STTëŠ” ê³„ì† ì§„í–‰
      }

      // 2. AudioContext ìƒì„±
      audioContext = new (window.AudioContext || window.webkitAudioContext)()

      // 3. AudioWorklet ë¡œë“œ (PCM ë³€í™˜ìš©)
      await audioContext.audioWorklet.addModule('/pcm-processor.js')

      // 4. AudioWorkletNode ìƒì„±
      audioWorkletNode = new AudioWorkletNode(audioContext, 'pcm-processor')

      // 5. ë§ˆì´í¬ ì—°ê²°
      sourceNode = audioContext.createMediaStreamSource(audioStream)
      sourceNode.connect(audioWorkletNode)

      // 6. WebSocket ì—°ê²° (ë‹¨ì¼ ì–¸ì–´)
      wsConnection = createMultiLangSTTStream(language, {
        onConnected: () => {
          console.log('âœ… Realtime STT connected')

          setTimeout(() => {
            if (wsConnection && wsConnection.ws.readyState === WebSocket.OPEN) {
              // PCM ë°ì´í„° ì „ì†¡ ì‹œì‘
              audioWorkletNode.port.onmessage = (event) => {
                if (wsConnection && wsConnection.ws.readyState === WebSocket.OPEN) {
                  wsConnection.ws.send(event.data)
                }
              }

              isRecording.value = true
              isConnected.value = true
              isConnecting.value = false

              // ë…¹ìŒ ì‹œê°„ íƒ€ì´ë¨¸ ì‹œì‘
              recordingInterval = setInterval(() => {
                recordingTime.value++
              }, 1000)
            } else {
              error.value = 'WebSocket ì—°ê²°ì´ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤'
              isConnecting.value = false
              cleanup()
            }
          }, 200)
        },

        onRecognizing: (message) => {
          // ì¤‘ê°„ ì¸ì‹ ê²°ê³¼
          interimText.value = message.text || ''
        },

        onRecognized: (message) => {
          // ìµœì¢… ì¸ì‹ ê²°ê³¼ - ë²ˆì—­ì€ ë¬´ì‹œí•˜ê³  ì¸ì‹ëœ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©
          const text = message.text?.trim()
          if (text) {
            finalTexts.value.push(text)
            interimText.value = ''
            console.log('ğŸ¤ Recognized:', text)
          }
        },

        onError: (errorMessage) => {
          console.error('âŒ Realtime STT error:', errorMessage)
          error.value = errorMessage
        },

        onEnd: () => {
          console.log('ğŸ”š Realtime STT ended')
          isConnected.value = false
        }
      })

    } catch (err) {
      console.error('âŒ Failed to start realtime STT:', err)
      error.value = err.message || 'ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨'
      isConnecting.value = false
      cleanup()
      throw err
    }
  }

  /**
   * ë…¹ìŒ ì¤‘ì§€ ë° ê²°ê³¼ ë°˜í™˜
   *
   * @returns {Object} { text: string, audioBlob: Blob|null }
   */
  function stopRecording() {
    // íƒ€ì´ë¨¸ ì¤‘ì§€
    if (recordingInterval) {
      clearInterval(recordingInterval)
      recordingInterval = null
    }

    // ìµœì¢… í…ìŠ¤íŠ¸ ìº¡ì²˜ (ì¤‘ì§€ ì „ì—)
    const resultText = fullText.value

    // MediaRecorder ì¤‘ì§€ (ì˜¤ë””ì˜¤ ìº¡ì²˜ ì™„ë£Œ)
    let capturedAudioBlob = null
    if (mediaRecorder && mediaRecorder.state !== 'inactive') {
      mediaRecorder.stop()
      // ë™ê¸°ì ìœ¼ë¡œ Blob ìƒì„± (onstop ëŒ€ê¸°í•˜ì§€ ì•ŠìŒ)
      if (audioChunks.length > 0) {
        capturedAudioBlob = new Blob(audioChunks, { type: 'audio/webm' })
        audioBlob.value = capturedAudioBlob
        console.log('ğŸ¤ Audio captured immediately:', capturedAudioBlob.size, 'bytes')
      }
    }

    // ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    cleanup()

    console.log('â¹ï¸ Recording stopped, text:', resultText)
    return {
      text: resultText,
      audioBlob: capturedAudioBlob
    }
  }

  /**
   * ë¦¬ì†ŒìŠ¤ ì •ë¦¬
   */
  function cleanup() {
    try {
      // MediaRecorder ì •ë¦¬
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        try {
          mediaRecorder.stop()
        } catch (e) {
          // ì´ë¯¸ ì¤‘ì§€ë¨
        }
      }
      mediaRecorder = null

      // Audio ë…¸ë“œ ì •ë¦¬
      if (sourceNode) {
        sourceNode.disconnect()
        sourceNode = null
      }

      if (audioWorkletNode) {
        audioWorkletNode.disconnect()
        audioWorkletNode.port.onmessage = null
        audioWorkletNode = null
      }

      if (audioContext && audioContext.state !== 'closed') {
        audioContext.close()
        audioContext = null
      }

      if (audioStream) {
        audioStream.getTracks().forEach(track => track.stop())
        audioStream = null
      }

      // WebSocket ì •ë¦¬
      if (wsConnection) {
        wsConnection.close()
        wsConnection = null
      }

      // ìƒíƒœ ì´ˆê¸°í™”
      isRecording.value = false
      isConnected.value = false
      isConnecting.value = false

    } catch (err) {
      console.error('âŒ Cleanup error:', err)
    }
  }

  /**
   * ê²°ê³¼ ì´ˆê¸°í™”
   */
  function clearResults() {
    interimText.value = ''
    finalTexts.value = []
    recordingTime.value = 0
    error.value = null
    audioBlob.value = null
    audioChunks = []
  }

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  onUnmounted(() => {
    if (recordingInterval) {
      clearInterval(recordingInterval)
    }
    cleanup()
  })

  return {
    // ìƒíƒœ
    isRecording,
    isConnected,
    isConnecting,
    error,

    // ì¸ì‹ ê²°ê³¼
    interimText,
    finalTexts,
    fullText,
    recordingTime,
    audioBlob,  // ë…¹ìŒëœ ì˜¤ë””ì˜¤ Blob (ë°œìŒ í‰ê°€ìš©)

    // ë©”ì„œë“œ
    startRecording,
    stopRecording,
    clearResults
  }
}
