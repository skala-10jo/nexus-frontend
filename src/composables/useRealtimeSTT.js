/**
 * Real-time STT Composable for Conversation Practice
 *
 * íšŒí™”ì—°ìŠµ í˜ì´ì§€ìš© ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ Composable
 * useMultiLanguageSTT.jsì˜ ì•„í‚¤í…ì²˜ë¥¼ ì¬ì‚¬ìš©í•˜ë˜, ë²ˆì—­ ì—†ì´ ë‹¨ì¼ ì–¸ì–´ STTì— ì§‘ì¤‘
 *
 * ì£¼ìš” ê¸°ëŠ¥:
 * - ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ (WebSocket ê¸°ë°˜)
 * - ì¤‘ê°„ ì¸ì‹ ê²°ê³¼ (recognizing) í‘œì‹œ
 * - ìµœì¢… ì¸ì‹ ê²°ê³¼ (recognized) ëˆ„ì 
 * - ë…¹ìŒ ì¤‘ì§€ ì‹œ ì „ì²´ í…ìŠ¤íŠ¸ ë°˜í™˜
 *
 * @see useMultiLanguageSTT.js - ê¸°ë°˜ ì•„í‚¤í…ì²˜
 * @see voice_realtime.py - ë°±ì—”ë“œ WebSocket API
 */
import { ref, computed, onUnmounted } from 'vue'
import { createMultiLangSTTStream } from '../services/voiceService'

export function useRealtimeSTT() {
  // ìƒíƒœ
  const isRecording = ref(false)
  const isConnected = ref(false)
  const isConnecting = ref(false)
  const error = ref(null)

  // ì¸ì‹ ê²°ê³¼
  const interimText = ref('')       // ì¤‘ê°„ ì¸ì‹ ê²°ê³¼ (recognizing)
  const finalTexts = ref([])        // ìµœì¢… ì¸ì‹ ê²°ê³¼ ë°°ì—´ (recognized)
  const recordingTime = ref(0)      // ë…¹ìŒ ì‹œê°„ (ì´ˆ)

  // ë‚´ë¶€ ë¦¬ì†ŒìŠ¤
  let wsConnection = null
  let audioContext = null
  let audioWorkletNode = null
  let sourceNode = null
  let audioStream = null
  let recordingInterval = null

  /**
   * ì „ì²´ ì¸ì‹ëœ í…ìŠ¤íŠ¸ (ìµœì¢… í…ìŠ¤íŠ¸ + ì¤‘ê°„ í…ìŠ¤íŠ¸)
   */
  const fullText = computed(() => {
    const finals = finalTexts.value.join(' ')
    const interim = interimText.value
    return interim ? `${finals} ${interim}`.trim() : finals
  })

  /**
   * ì‹¤ì‹œê°„ STT ë…¹ìŒ ì‹œì‘
   *
   * @param {string} language - ì£¼ ì¸ì‹ ì–¸ì–´ (BCP-47 ì½”ë“œ, ì˜ˆ: 'en-US')
   * @param {string} secondaryLanguage - ë³´ì¡° ì–¸ì–´ (ì„ íƒì‚¬í•­, ë°±ì—”ë“œì—ì„œ ìµœì†Œ 2ê°œ í•„ìš”)
   */
  async function startRecording(language = 'en-US', secondaryLanguage = 'ko-KR') {
    if (isRecording.value || isConnecting.value) {
      console.warn('âš ï¸ Already recording or connecting')
      return
    }

    try {
      isConnecting.value = true
      error.value = null
      interimText.value = ''
      finalTexts.value = []
      recordingTime.value = 0

      // 1. ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
      audioStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 48000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        }
      })

      // 2. AudioContext ìƒì„±
      audioContext = new (window.AudioContext || window.webkitAudioContext)()

      // 3. AudioWorklet ë¡œë“œ (PCM ë³€í™˜ìš©)
      await audioContext.audioWorklet.addModule('/pcm-processor.js')

      // 4. AudioWorkletNode ìƒì„±
      audioWorkletNode = new AudioWorkletNode(audioContext, 'pcm-processor')

      // 5. ë§ˆì´í¬ ì—°ê²°
      sourceNode = audioContext.createMediaStreamSource(audioStream)
      sourceNode.connect(audioWorkletNode)

      // 6. WebSocket ì—°ê²° (ë°±ì—”ë“œëŠ” ìµœì†Œ 2ê°œ ì–¸ì–´ í•„ìš”)
      const selectedLanguages = [language, secondaryLanguage]

      wsConnection = createMultiLangSTTStream(selectedLanguages, {
        onConnected: () => {
          console.log('âœ… Realtime STT connected')

          setTimeout(() => {
            if (wsConnection && wsConnection.ws.readyState === WebSocket.OPEN) {
              // PCM ë°ì´í„° ì „ì†¡ ì‹œì‘
              audioWorkletNode.port.onmessage = (event) => {
                if (wsConnection && wsConnection.ws.readyState === WebSocket.OPEN) {
                  wsConnection.ws.send(event.data)
                }
              }

              isRecording.value = true
              isConnected.value = true
              isConnecting.value = false

              // ë…¹ìŒ ì‹œê°„ íƒ€ì´ë¨¸ ì‹œì‘
              recordingInterval = setInterval(() => {
                recordingTime.value++
              }, 1000)
            } else {
              error.value = 'WebSocket ì—°ê²°ì´ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤'
              isConnecting.value = false
              cleanup()
            }
          }, 200)
        },

        onRecognizing: (message) => {
          // ì¤‘ê°„ ì¸ì‹ ê²°ê³¼
          interimText.value = message.text || ''
        },

        onRecognized: (message) => {
          // ìµœì¢… ì¸ì‹ ê²°ê³¼ - ë²ˆì—­ì€ ë¬´ì‹œí•˜ê³  ì¸ì‹ëœ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©
          const text = message.text?.trim()
          if (text) {
            finalTexts.value.push(text)
            interimText.value = ''
            console.log('ğŸ¤ Recognized:', text)
          }
        },

        onError: (errorMessage) => {
          console.error('âŒ Realtime STT error:', errorMessage)
          error.value = errorMessage
        },

        onEnd: () => {
          console.log('ğŸ”š Realtime STT ended')
          isConnected.value = false
        }
      })

    } catch (err) {
      console.error('âŒ Failed to start realtime STT:', err)
      error.value = err.message || 'ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨'
      isConnecting.value = false
      cleanup()
      throw err
    }
  }

  /**
   * ë…¹ìŒ ì¤‘ì§€ ë° ìµœì¢… í…ìŠ¤íŠ¸ ë°˜í™˜
   *
   * @returns {string} ì „ì²´ ì¸ì‹ëœ í…ìŠ¤íŠ¸
   */
  function stopRecording() {
    // íƒ€ì´ë¨¸ ì¤‘ì§€
    if (recordingInterval) {
      clearInterval(recordingInterval)
      recordingInterval = null
    }

    // ìµœì¢… í…ìŠ¤íŠ¸ ìº¡ì²˜ (ì¤‘ì§€ ì „ì—)
    const result = fullText.value

    // ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    cleanup()

    console.log('â¹ï¸ Recording stopped, text:', result)
    return result
  }

  /**
   * ë¦¬ì†ŒìŠ¤ ì •ë¦¬
   */
  function cleanup() {
    try {
      // Audio ë…¸ë“œ ì •ë¦¬
      if (sourceNode) {
        sourceNode.disconnect()
        sourceNode = null
      }

      if (audioWorkletNode) {
        audioWorkletNode.disconnect()
        audioWorkletNode.port.onmessage = null
        audioWorkletNode = null
      }

      if (audioContext && audioContext.state !== 'closed') {
        audioContext.close()
        audioContext = null
      }

      if (audioStream) {
        audioStream.getTracks().forEach(track => track.stop())
        audioStream = null
      }

      // WebSocket ì •ë¦¬
      if (wsConnection) {
        wsConnection.close()
        wsConnection = null
      }

      // ìƒíƒœ ì´ˆê¸°í™”
      isRecording.value = false
      isConnected.value = false
      isConnecting.value = false

    } catch (err) {
      console.error('âŒ Cleanup error:', err)
    }
  }

  /**
   * ê²°ê³¼ ì´ˆê¸°í™”
   */
  function clearResults() {
    interimText.value = ''
    finalTexts.value = []
    recordingTime.value = 0
    error.value = null
  }

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  onUnmounted(() => {
    if (recordingInterval) {
      clearInterval(recordingInterval)
    }
    cleanup()
  })

  return {
    // ìƒíƒœ
    isRecording,
    isConnected,
    isConnecting,
    error,

    // ì¸ì‹ ê²°ê³¼
    interimText,
    finalTexts,
    fullText,
    recordingTime,

    // ë©”ì„œë“œ
    startRecording,
    stopRecording,
    clearResults
  }
}
