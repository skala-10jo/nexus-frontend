/**
 * ìŒì„± TTS ì„œë¹„ìŠ¤ (Azure Speech SDK Avatar ì§€ì›)
 *
 * Azure Speech SDKë¥¼ ì‚¬ìš©í•˜ì—¬ AI ì‘ë‹µì„ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
 * Azure AI Speech Avatar WebRTC ì—°ê²° ì§€ì›
 */
import * as SpeechSDK from 'microsoft-cognitiveservices-speech-sdk'
import { pythonAPI } from './api'

const voiceAvatarService = {
  // í˜„ì¬ ì˜¤ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ë° ì–¸ì–´
  _currentAudioElement: null,
  _currentLanguage: 'en-US',
  _isPlaying: false,

  // Azure Speech SDK Avatar ê´€ë ¨
  _speechConfig: null,
  _avatarConfig: null,
  _avatarSynthesizer: null,
  _peerConnection: null,
  _avatarVideoElement: null,
  _avatarAudioElement: null, // Audio track ì „ìš© element
  _isAvatarConnected: false,
  _isSpeaking: false,

  /**
   * ìŒì„± TTS ì´ˆê¸°í™”
   * @param {HTMLAudioElement} audioElement - ì˜¤ë””ì˜¤ë¥¼ ì¬ìƒí•  audio ì—˜ë¦¬ë¨¼íŠ¸
   * @param {string} language - ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: en-US)
   * @returns {Promise<void>}
   */
  async initialize(audioElement, language = 'en-US') {
    console.log('ìŒì„± TTS ì´ˆê¸°í™”', { language })

    // ì˜¤ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ì €ì¥
    this._currentAudioElement = audioElement
    this._currentLanguage = language

    console.log('âœ… ìŒì„± TTS ì¤€ë¹„ ì™„ë£Œ')
  },

  /**
   * í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜ ë° ì¬ìƒ
   * @param {string} text - ë§í•  í…ìŠ¤íŠ¸
   * @returns {Promise<void>}
   */
  async speak(text) {
    if (!text || !text.trim()) {
      console.warn('TTS: ë¹ˆ í…ìŠ¤íŠ¸')
      return
    }

    if (!this._currentAudioElement) {
      throw new Error('ìŒì„± TTSê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
    }

    try {
      this._isPlaying = true
      console.log(`TTS ìŒì„± ìƒì„±: "${text.substring(0, 50)}..."`)

      // ë°±ì—”ë“œì—ì„œ ìŒì„± ìƒì„±
      const response = await pythonAPI.post('/avatar/synthesize', {
        text,
        language: this._currentLanguage || 'en-US'
      }, {
        responseType: 'blob'  // ì˜¤ë””ì˜¤ íŒŒì¼ì„ blobìœ¼ë¡œ ë°›ìŒ
      })

      // Blob URL ìƒì„±
      const audioBlob = response.data
      const audioUrl = URL.createObjectURL(audioBlob)

      console.log('ìŒì„± ìƒì„± ì™„ë£Œ, ì¬ìƒ ì‹œì‘')

      // ì˜¤ë””ì˜¤ ì¬ìƒ
      this._currentAudioElement.src = audioUrl
      await this._currentAudioElement.play()

      // ì¬ìƒ ì™„ë£Œ ëŒ€ê¸°
      return new Promise((resolve, reject) => {
        this._currentAudioElement.onended = () => {
          this._isPlaying = false
          URL.revokeObjectURL(audioUrl)  // ë©”ëª¨ë¦¬ ì •ë¦¬
          console.log('ìŒì„± ì¬ìƒ ì™„ë£Œ')
          resolve()
        }

        this._currentAudioElement.onerror = (error) => {
          this._isPlaying = false
          URL.revokeObjectURL(audioUrl)
          console.error('ìŒì„± ì¬ìƒ ì‹¤íŒ¨:', error)
          reject(new Error('ìŒì„± ì¬ìƒ ì‹¤íŒ¨'))
        }
      })
    } catch (error) {
      this._isPlaying = false
      console.error('TTS ì‹¤íŒ¨:', error)
      throw error
    }
  },

  /**
   * ìŒì„± ì¤‘ì§€ ë° ë¦¬ì†ŒìŠ¤ ì •ë¦¬
   */
  async stop() {
    try {
      if (this._currentAudioElement) {
        this._currentAudioElement.pause()
        this._currentAudioElement.src = ''
      }

      this._isPlaying = false
      console.log('ìŒì„± TTS stopped and cleaned up')
    } catch (error) {
      console.error('TTS stop failed:', error)
    }
  },

  /**
   * ì¬ìƒ ì¤‘ì¸ì§€ í™•ì¸
   * @returns {boolean}
   */
  isPlaying() {
    return this._isPlaying
  },

  /**
   * ì–¸ì–´ì— ë§ëŠ” ìŒì„± ë°˜í™˜
   * @param {string} language - ì–¸ì–´ ì½”ë“œ
   * @returns {string} ìŒì„± ì´ë¦„
   */
  _getVoiceForLanguage(language) {
    // Azure Avatar ì§€ì› ìŒì„± (Neural voices)
    const voiceMap = {
      'en-US': 'en-US-JennyNeural',
      'en-GB': 'en-GB-SoniaNeural',
      'ko-KR': 'ko-KR-SunHiNeural',
      'ja-JP': 'ja-JP-NanamiNeural',
      'zh-CN': 'zh-CN-XiaoxiaoNeural',
      'es-ES': 'es-ES-ElviraNeural',
      'fr-FR': 'fr-FR-DeniseNeural',
      'de-DE': 'de-DE-KatjaNeural'
    }
    return voiceMap[language] || 'en-US-JennyNeural'
  },

  // =========== Avatar WebRTC ê´€ë ¨ ë©”ì„œë“œ (Azure Speech SDK) ===========

  /**
   * Avatar WebRTC ì—°ê²° ì´ˆê¸°í™” (Azure Speech SDK ì‚¬ìš©)
   * @param {HTMLVideoElement} videoElement - ì•„ë°”íƒ€ë¥¼ í‘œì‹œí•  video ì—˜ë¦¬ë¨¼íŠ¸
   * @param {Object} options - ì˜µì…˜ (character, style, language)
   * @returns {Promise<void>}
   */
  async initializeAvatar(videoElement, options = {}) {
    console.log('ğŸ­ Avatar ì´ˆê¸°í™” ì‹œì‘ (Azure Speech SDK)', options)

    this._avatarVideoElement = videoElement
    const character = options.character || 'lisa'
    const style = options.style || 'casual-sitting'
    const language = options.language || this._currentLanguage || 'en-US'

    try {
      // 1. ë°±ì—”ë“œì—ì„œ í† í° ë° ICE ì„œë²„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
      const configResponse = await pythonAPI.get('/avatar/config')
      if (!configResponse.data.success) {
        throw new Error('Avatar config fetch failed')
      }

      const config = configResponse.data.data
      console.log('âœ… Avatar ì„¤ì • ë¡œë“œ ì™„ë£Œ:', {
        region: config.region,
        character: config.avatar_character,
        hasToken: !!config.token
      })

      // 2. Azure Speech SDK ì„¤ì •
      this._speechConfig = SpeechSDK.SpeechConfig.fromAuthorizationToken(
        config.token,
        config.region
      )

      // ìŒì„± ì„¤ì •
      const voiceName = this._getVoiceForLanguage(language)
      this._speechConfig.speechSynthesisVoiceName = voiceName
      console.log('ğŸ¤ Voice ì„¤ì •:', voiceName)

      // 3. Avatar ì„¤ì • (VideoFormat í¬í•¨ - 16:9 ë¹„ìœ¨ í•„ìˆ˜!)
      const videoFormat = new SpeechSDK.AvatarVideoFormat()
      videoFormat.width = 1920
      videoFormat.height = 1080

      this._avatarConfig = new SpeechSDK.AvatarConfig(character, style, videoFormat)
      this._avatarConfig.customized = false
      this._avatarConfig.backgroundColor = '#000000FF' // ê²€ì • ë°°ê²½

      console.log('ğŸ­ Avatar ìºë¦­í„° ì„¤ì •:', { character, style, videoFormat: '1920x1080' })

      // 4. WebRTC PeerConnection ì„¤ì •
      await this._setupWebRTCWithSDK(config.ice_servers)

      // 5. AvatarSynthesizer ìƒì„±
      this._avatarSynthesizer = new SpeechSDK.AvatarSynthesizer(
        this._speechConfig,
        this._avatarConfig
      )

      // 6. Avatar ì‹œì‘
      await this._startAvatarConnection()

      console.log('âœ… Avatar ì´ˆê¸°í™” ì™„ë£Œ')
    } catch (error) {
      console.error('âŒ Avatar ì´ˆê¸°í™” ì‹¤íŒ¨:', error)
      throw error
    }
  },

  /**
   * WebRTC PeerConnection ì„¤ì • (Azure Speech SDKìš©)
   * @private
   */
  async _setupWebRTCWithSDK(iceServers) {
    console.log('ğŸ”— WebRTC PeerConnection ì„¤ì • ì¤‘...', iceServers)

    // ICE ì„œë²„ ì„¤ì • (Azure Avatar ê³µì‹ ìƒ˜í”Œ ë°©ì‹)
    const configuration = {
      iceServers: [
        {
          urls: iceServers.urls,
          username: iceServers.username,
          credential: iceServers.credential
        }
      ]
    }

    // PeerConnection ìƒì„±
    this._peerConnection = new RTCPeerConnection(configuration)

    // ì–‘ë°©í–¥ íŠ¸ëœì‹œë²„ ì¶”ê°€ (Azure Avatar SDK ìš”êµ¬ì‚¬í•­ - sendrecv í•„ìˆ˜!)
    this._peerConnection.addTransceiver('video', { direction: 'sendrecv' })
    this._peerConnection.addTransceiver('audio', { direction: 'sendrecv' })

    // Audio element ìƒì„± (ìˆ¨ê¹€) - audio track ì „ìš©
    if (!this._avatarAudioElement) {
      this._avatarAudioElement = document.createElement('audio')
      this._avatarAudioElement.autoplay = true
      this._avatarAudioElement.id = 'avatar-audio-player'
      document.body.appendChild(this._avatarAudioElement)
      console.log('ğŸ”Š Audio element ìƒì„±ë¨')
    }

    // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
    this._peerConnection.ontrack = (event) => {
      console.log('ğŸ¬ Remote track received:', event.track.kind, {
        trackId: event.track.id,
        streamId: event.streams?.[0]?.id
      })

      if (event.track.kind === 'video') {
        // Video track â†’ video element
        if (this._avatarVideoElement && event.streams && event.streams[0]) {
          this._avatarVideoElement.srcObject = event.streams[0]
          console.log('ğŸ¬ Video stream attached to video element', {
            streamId: event.streams[0].id,
            videoTracks: event.streams[0].getVideoTracks().length
          })
        }
      } else if (event.track.kind === 'audio') {
        // Audio track â†’ audio element
        if (this._avatarAudioElement && event.streams && event.streams[0]) {
          this._avatarAudioElement.srcObject = event.streams[0]
          console.log('ğŸ”Š Audio stream attached to audio element', {
            streamId: event.streams[0].id,
            audioTracks: event.streams[0].getAudioTracks().length
          })

          // ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œë„
          this._avatarAudioElement.play().catch(err => {
            console.warn('ğŸ”Š Audio autoplay blocked:', err)
          })
        }
      }
    }

    this._peerConnection.oniceconnectionstatechange = () => {
      const state = this._peerConnection?.iceConnectionState
      console.log('ğŸ”— ICE connection state:', state)
      this._isAvatarConnected = state === 'connected' || state === 'completed'
    }

    this._peerConnection.onconnectionstatechange = () => {
      console.log('ğŸ“¡ Connection state:', this._peerConnection?.connectionState)
    }

    this._peerConnection.onicegatheringstatechange = () => {
      console.log('ğŸ§Š ICE gathering state:', this._peerConnection?.iceGatheringState)
    }

    this._peerConnection.onicecandidate = (event) => {
      if (event.candidate) {
        console.log('ğŸ§Š ICE candidate:', event.candidate.type)
      } else {
        console.log('ğŸ§Š ICE gathering complete')
      }
    }

    console.log('âœ… WebRTC PeerConnection ì„¤ì • ì™„ë£Œ')
  },

  /**
   * Avatar WebRTC ì—°ê²° ì‹œì‘ (SDP êµí™˜)
   * @private
   */
  async _startAvatarConnection() {
    console.log('ğŸš€ Avatar ì—°ê²° ì‹œì‘...')

    return new Promise((resolve, reject) => {
      this._avatarSynthesizer.startAvatarAsync(this._peerConnection).then(
        (result) => {
          console.log('ğŸ“‹ Avatar startAvatarAsync result:', {
            reason: result.reason,
            reasonName: SpeechSDK.ResultReason[result.reason],
            resultId: result.resultId
          })

          if (result.reason === SpeechSDK.ResultReason.SynthesizingAudioCompleted) {
            console.log('âœ… Avatar ì—°ê²° ì„±ê³µ')
            this._isAvatarConnected = true

            // ë¹„ë””ì˜¤ ì¬ìƒ ì‹œì‘
            if (this._avatarVideoElement) {
              this._avatarVideoElement.play().catch(err => {
                console.warn('Video autoplay blocked:', err)
              })
            }

            // ì—°ê²° í›„ ì§§ì€ ì¸ì‚¬ë§ë¡œ ì•„ë°”íƒ€ í™œì„±í™” (idle ìƒíƒœ íƒˆì¶œ)
            setTimeout(async () => {
              if (this._avatarSynthesizer && this._isAvatarConnected) {
                console.log('ğŸ­ Avatar í™œì„±í™” ì¸ì‚¬ë§ ë°œí™”...')

                try {
                  // Promise ë°©ì‹ ì‚¬ìš© (ê³µì‹ ìƒ˜í”Œ ë°©ì‹)
                  const res = await this._avatarSynthesizer.speakTextAsync('Hello! I am ready.')
                  console.log('ğŸ­ ì¸ì‚¬ë§ ë°œí™” ê²°ê³¼:', {
                    reason: res.reason,
                    reasonName: SpeechSDK.ResultReason[res.reason]
                  })
                  if (res.reason === SpeechSDK.ResultReason.SynthesizingAudioCompleted) {
                    console.log('âœ… Avatar í™œì„±í™” ì™„ë£Œ - ì•„ë°”íƒ€ê°€ ë³´ì—¬ì•¼ í•©ë‹ˆë‹¤!')
                  } else if (res.reason === SpeechSDK.ResultReason.Canceled) {
                    const details = SpeechSDK.CancellationDetails.fromResult(res)
                    console.error('âŒ ì¸ì‚¬ë§ ì·¨ì†Œ:', details.reason, details.errorDetails)
                  }
                } catch (err) {
                  console.error('âŒ Avatar ì¸ì‚¬ë§ ì‹¤íŒ¨:', err)
                }
              }
            }, 1000)

            resolve(result)
          } else if (result.reason === SpeechSDK.ResultReason.Canceled) {
            // ì·¨ì†Œëœ ê²½ìš° ìƒì„¸ ì •ë³´ í™•ì¸
            const cancellation = SpeechSDK.CancellationDetails.fromResult(result)
            console.error('âŒ Avatar ì—°ê²° ì·¨ì†Œë¨:', {
              reason: cancellation.reason,
              reasonName: SpeechSDK.CancellationReason[cancellation.reason],
              errorCode: cancellation.ErrorCode,
              errorDetails: cancellation.errorDetails
            })
            reject(new Error(`Avatar ì—°ê²° ì·¨ì†Œ: ${cancellation.errorDetails || cancellation.reason}`))
          } else {
            const error = new Error(`Avatar ì—°ê²° ì‹¤íŒ¨: ${result.reason} (${SpeechSDK.ResultReason[result.reason]})`)
            console.error('âŒ', error.message)
            reject(error)
          }
        },
        (error) => {
          console.error('âŒ Avatar ì—°ê²° ì—ëŸ¬:', error)
          reject(error)
        }
      )
    })
  },

  /**
   * Avatar ì„¸ì…˜ ì‹œì‘ (WebRTC ì—°ê²°)
   * @param {string} character - ì•„ë°”íƒ€ ìºë¦­í„° (lisa, harry ë“±)
   * @param {string} style - ì•„ë°”íƒ€ ìŠ¤íƒ€ì¼ (casual-sitting ë“±)
   * @returns {Promise<Object>} ì„¸ì…˜ ì •ë³´
   */
  async startAvatarSession(character = 'lisa', style = 'casual-sitting') {
    console.log('ğŸš€ Avatar ì„¸ì…˜ ì‹œì‘:', { character, style })

    // Avatarê°€ ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ì´ˆê¸°í™”
    if (!this._avatarSynthesizer && this._avatarVideoElement) {
      await this.initializeAvatar(this._avatarVideoElement, { character, style })
    }

    return {
      session_id: `avatar_${Date.now()}`,
      character,
      style,
      connected: this._isAvatarConnected
    }
  },

  /**
   * Avatarì— í…ìŠ¤íŠ¸ ì „ì†¡ (ë§í•˜ê¸°) - Azure Speech SDK ì‚¬ìš©
   * @param {string} text - ë§í•  í…ìŠ¤íŠ¸
   * @param {string} language - ì–¸ì–´ ì½”ë“œ
   * @returns {Promise<void>}
   */
  async speakWithAvatar(text, language = 'en-US') {
    if (!text || !text.trim()) {
      console.warn('Avatar TTS: ë¹ˆ í…ìŠ¤íŠ¸')
      return
    }

    if (!this._avatarSynthesizer) {
      console.error('Avatarê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤')
      throw new Error('Avatar not initialized')
    }

    if (this._isSpeaking) {
      console.warn('Avatarê°€ ì´ë¯¸ ë§í•˜ê³  ìˆìŠµë‹ˆë‹¤')
      return
    }

    this._isSpeaking = true
    console.log(`ğŸ—£ï¸ Avatar speaking: "${text.substring(0, 50)}..."`)

    try {
      // ìŒì„± ì„¤ì • ì—…ë°ì´íŠ¸ (ì–¸ì–´ê°€ ë³€ê²½ëœ ê²½ìš°)
      const voiceName = this._getVoiceForLanguage(language)
      if (this._speechConfig.speechSynthesisVoiceName !== voiceName) {
        this._speechConfig.speechSynthesisVoiceName = voiceName
        console.log('ğŸ¤ Voice ë³€ê²½:', voiceName)
      }

      // Promise ë°©ì‹ ì‚¬ìš© (ê³µì‹ ìƒ˜í”Œ ë°©ì‹)
      const result = await this._avatarSynthesizer.speakTextAsync(text)
      this._isSpeaking = false

      if (result.reason === SpeechSDK.ResultReason.SynthesizingAudioCompleted) {
        console.log('âœ… Avatar ë°œí™” ì™„ë£Œ')
        return result
      } else if (result.reason === SpeechSDK.ResultReason.Canceled) {
        const cancellation = SpeechSDK.CancellationDetails.fromResult(result)
        console.error('âŒ Avatar ë°œí™” ì·¨ì†Œ:', cancellation.reason, cancellation.errorDetails)
        throw new Error(`Avatar speak canceled: ${cancellation.errorDetails}`)
      } else {
        console.warn('âš ï¸ Avatar ë°œí™” ê²°ê³¼:', result.reason)
        return result
      }
    } catch (error) {
      this._isSpeaking = false
      console.error('âŒ Avatar speak ì‹¤íŒ¨:', error)
      throw error
    }
  },

  /**
   * Avatar ë°œí™” ì¤‘ì§€
   */
  async stopAvatarSpeaking() {
    if (!this._avatarSynthesizer || !this._isSpeaking) {
      return
    }

    console.log('ğŸ›‘ Avatar ë°œí™” ì¤‘ì§€')
    try {
      await this._avatarSynthesizer.stopSpeakingAsync()
      this._isSpeaking = false
      console.log('âœ… Avatar ë°œí™” ì¤‘ì§€ ì™„ë£Œ')
    } catch (error) {
      console.error('âŒ Avatar ë°œí™” ì¤‘ì§€ ì‹¤íŒ¨:', error)
    }
  },

  /**
   * Avatar ì—°ê²° í•´ì œ
   */
  async disconnectAvatar() {
    console.log('ğŸ”Œ Avatar ì—°ê²° í•´ì œ')

    // ë°œí™” ì¤‘ì§€
    if (this._isSpeaking) {
      await this.stopAvatarSpeaking()
    }

    // AvatarSynthesizer ì¢…ë£Œ
    if (this._avatarSynthesizer) {
      try {
        await this._avatarSynthesizer.stopAvatarAsync()
        this._avatarSynthesizer.close()
      } catch (error) {
        console.warn('AvatarSynthesizer close warning:', error)
      }
      this._avatarSynthesizer = null
    }

    // PeerConnection ì¢…ë£Œ
    if (this._peerConnection) {
      this._peerConnection.close()
      this._peerConnection = null
    }

    // Video element ì •ë¦¬
    if (this._avatarVideoElement) {
      this._avatarVideoElement.srcObject = null
    }

    // Audio element ì •ë¦¬
    if (this._avatarAudioElement) {
      this._avatarAudioElement.pause()
      this._avatarAudioElement.srcObject = null
      this._avatarAudioElement.remove()
      this._avatarAudioElement = null
    }

    // ìƒíƒœ ì´ˆê¸°í™”
    this._isAvatarConnected = false
    this._speechConfig = null
    this._avatarConfig = null
    this._isSpeaking = false

    console.log('âœ… Avatar ì—°ê²° í•´ì œ ì™„ë£Œ')
  },

  /**
   * Avatar ì—°ê²° ìƒíƒœ í™•ì¸
   * @returns {boolean}
   */
  isAvatarConnected() {
    return this._isAvatarConnected
  },

  /**
   * Avatar ë°œí™” ì¤‘ì¸ì§€ í™•ì¸
   * @returns {boolean}
   */
  isAvatarSpeaking() {
    return this._isSpeaking
  }
}

export default voiceAvatarService
