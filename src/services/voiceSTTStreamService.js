/**
 * ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ WebSocket ì„œë¹„ìŠ¤
 *
 * WebSocketì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
 */

class VoiceSTTStreamService {
  constructor() {
    this.ws = null
    this.mediaRecorder = null
    this.stream = null
    this.isRecording = false

    // ì½œë°± í•¨ìˆ˜ë“¤
    this.onInterim = null  // (text) => {}
    this.onFinal = null    // (text, confidence) => {}
    this.onError = null    // (error) => {}
    this.onClose = null    // () => {}

    // ë°œìŒ í‰ê°€ìš© ì˜¤ë””ì˜¤ ë…¹ìŒ
    this.audioChunks = []  // MediaRecorderë¡œ ë…¹ìŒëœ ì²­í¬ë“¤
    this.mediaRecorderForPronunciation = null  // ë³„ë„ MediaRecorder
  }

  /**
   * WebSocket ì—°ê²° ë° ë…¹ìŒ ì‹œì‘
   * @param {Object} options - ì˜µì…˜
   * @param {string} options.language - ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: en-US)
   * @param {function} options.onInterim - interim ê²°ê³¼ ì½œë°±
   * @param {function} options.onFinal - final ê²°ê³¼ ì½œë°±
   * @param {function} options.onError - ì—ëŸ¬ ì½œë°±
   * @param {function} options.onClose - ì—°ê²° ì¢…ë£Œ ì½œë°±
   * @returns {Promise<void>}
   */
  async startStreaming({
    language = 'en-US',
    onInterim = null,
    onFinal = null,
    onError = null,
    onClose = null
  }) {
    try {
      // ì½œë°± ì„¤ì •
      this.onInterim = onInterim
      this.onFinal = onFinal
      this.onError = onError
      this.onClose = onClose

      // 1. ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ê°€ì ¸ì˜¤ê¸°
      this.stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 16000  // Azure Speech ê¶Œì¥
        }
      })

      console.log('ğŸ¤ Microphone stream acquired')

      // 2. WebSocket ì—°ê²°
      const token = localStorage.getItem('token')
      if (!token) {
        throw new Error('ì¸ì¦ í† í°ì´ ì—†ìŠµë‹ˆë‹¤. ë¡œê·¸ì¸í•´ì£¼ì„¸ìš”.')
      }

      // WebSocket URL (í™˜ê²½ì— ë”°ë¼ ë³€ê²½)
      const wsUrl = import.meta.env.VITE_WS_URL || 'ws://localhost:8000/api/ai/voice/ws/stt'
      this.ws = new WebSocket(wsUrl)

      // WebSocket ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡
      this.setupWebSocketHandlers()

      // WebSocket ì—°ê²° ëŒ€ê¸°
      await this.waitForOpen()

      console.log('ğŸ”— WebSocket connected')

      // 3. ì¸ì¦
      this.ws.send(JSON.stringify({
        type: 'auth',
        token: token
      }))

      // ì¸ì¦ ì„±ê³µ ëŒ€ê¸°
      await this.waitForAuthSuccess()

      console.log('âœ… Authentication successful')

      // 4. ì„¤ì •
      this.ws.send(JSON.stringify({
        type: 'config',
        language: language,
        enable_diarization: false
      }))

      console.log(`âš™ï¸ Config sent: language=${language}`)

      // 5. MediaRecorder ì„¤ì • ë° ë…¹ìŒ ì‹œì‘
      await this.startRecording()

      console.log('ğŸ™ï¸ Recording started')

      this.isRecording = true

    } catch (error) {
      console.error('Streaming start failed:', error)
      this.cleanup()

      if (this.onError) {
        this.onError(error.message || 'ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì‹œì‘ ì‹¤íŒ¨')
      }

      throw error
    }
  }

  /**
   * WebSocket ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
   * @private
   */
  setupWebSocketHandlers() {
    this.ws.onmessage = (event) => {
      try {
        const message = JSON.parse(event.data)
        this.handleWebSocketMessage(message)
      } catch (error) {
        console.error('WebSocket message parse error:', error)
      }
    }

    this.ws.onerror = (error) => {
      console.error('WebSocket error:', error)
      if (this.onError) {
        this.onError('WebSocket ì—°ê²° ì˜¤ë¥˜')
      }
    }

    this.ws.onclose = (event) => {
      console.log('WebSocket closed:', event.code, event.reason)

      if (!event.wasClean && this.onError) {
        this.onError('ì—°ê²°ì´ ëŠì–´ì¡ŒìŠµë‹ˆë‹¤')
      }

      if (this.onClose) {
        this.onClose()
      }

      this.cleanup()
    }
  }

  /**
   * WebSocket ë©”ì‹œì§€ ì²˜ë¦¬
   * @private
   */
  handleWebSocketMessage(message) {
    console.log('ğŸ“¨ Received:', message.type)

    switch (message.type) {
      case 'auth_success':
        console.log('âœ… Auth success:', message.user_id)
        break

      case 'auth_error':
        console.error('âŒ Auth error:', message.message)
        if (this.onError) {
          this.onError(message.message)
        }
        this.stopStreaming()
        break

      case 'interim':
        // ì‹¤ì‹œê°„ ì¸ì‹ ì¤‘ (íšŒìƒ‰ í…ìŠ¤íŠ¸)
        if (this.onInterim && message.text) {
          this.onInterim(message.text)
        }
        break

      case 'final':
        // ìµœì¢… ì¸ì‹ ì™„ë£Œ (ê²€ì • í…ìŠ¤íŠ¸)
        if (this.onFinal && message.text) {
          this.onFinal(message.text, message.confidence)
        }
        break

      case 'error':
        console.error('âŒ STT error:', message.message)
        if (this.onError) {
          this.onError(message.message)
        }
        break

      case 'closed':
        console.log('ğŸ”Œ Server closed connection')
        this.stopStreaming()
        break

      case 'session_stopped':
        console.log('â¹ï¸ Session stopped')
        break

      default:
        console.warn('Unknown message type:', message.type)
    }
  }

  /**
   * MediaRecorder ì„¤ì • ë° ë…¹ìŒ ì‹œì‘ (PCM ì¶”ì¶œ ë°©ì‹)
   * @private
   */
  async startRecording() {
    // AudioContext ìƒì„±
    const audioContext = new (window.AudioContext || window.webkitAudioContext)({
      sampleRate: 16000  // Azure Speech SDK ê¶Œì¥
    })

    // MediaStreamì„ AudioContextë¡œ ì—°ê²°
    const source = audioContext.createMediaStreamSource(this.stream)

    // ScriptProcessorNode ìƒì„± (PCM ë°ì´í„° ì¶”ì¶œ)
    // bufferSize: 4096, inputChannels: 1 (mono), outputChannels: 1
    const scriptNode = audioContext.createScriptProcessor(4096, 1, 1)

    scriptNode.onaudioprocess = (event) => {
      if (this.ws && this.ws.readyState === WebSocket.OPEN) {
        try {
          // Float32Array (PCM) ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
          const inputData = event.inputBuffer.getChannelData(0)

          // Float32 â†’ Int16 ë³€í™˜ (Azure Speech SDK ìš”êµ¬ í¬ë§·)
          const int16Data = new Int16Array(inputData.length)
          for (let i = 0; i < inputData.length; i++) {
            // -1.0 ~ 1.0 ë²”ìœ„ë¥¼ -32768 ~ 32767ë¡œ ë³€í™˜
            const s = Math.max(-1, Math.min(1, inputData[i]))
            int16Data[i] = s < 0 ? s * 0x8000 : s * 0x7FFF
          }

          // Int16Array â†’ Base64 ë³€í™˜
          const base64 = this.arrayBufferToBase64(int16Data.buffer)

          // WebSocketìœ¼ë¡œ ì „ì†¡
          this.ws.send(JSON.stringify({
            type: 'audio',
            data: base64
          }))

          console.log(`ğŸµ Audio chunk sent: ${(int16Data.buffer.byteLength / 1024).toFixed(2)}KB`)
        } catch (error) {
          console.error('Audio processing failed:', error)
        }
      }
    }

    // ì˜¤ë””ì˜¤ íŒŒì´í”„ë¼ì¸ ì—°ê²°
    source.connect(scriptNode)
    scriptNode.connect(audioContext.destination)

    // ë‚˜ì¤‘ì— ì •ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì €ì¥
    this.audioContext = audioContext
    this.scriptNode = scriptNode
    this.source = source

    // ë°œìŒ í‰ê°€ìš© MediaRecorder ì‹œì‘ (ê°™ì€ ìŠ¤íŠ¸ë¦¼ ì‚¬ìš©)
    this.audioChunks = []

    // MediaRecorder ì§€ì› í™•ì¸ ë° ìµœì  í¬ë§· ì„ íƒ
    let mimeType = 'audio/webm;codecs=opus'
    if (!MediaRecorder.isTypeSupported(mimeType)) {
      mimeType = 'audio/webm'
      if (!MediaRecorder.isTypeSupported(mimeType)) {
        mimeType = 'audio/ogg;codecs=opus'
        if (!MediaRecorder.isTypeSupported(mimeType)) {
          mimeType = '' // ë¸Œë¼ìš°ì € ê¸°ë³¸ê°’
        }
      }
    }

    this.mediaRecorderForPronunciation = new MediaRecorder(this.stream, {
      mimeType: mimeType || undefined
    })

    this.mediaRecorderForPronunciation.ondataavailable = (event) => {
      if (event.data && event.data.size > 0) {
        this.audioChunks.push(event.data)
        console.log(`ğŸ¤ Audio chunk for pronunciation: ${event.data.size} bytes`)
      }
    }

    this.mediaRecorderForPronunciation.start(1000) // 1ì´ˆë§ˆë‹¤ ì²­í¬ ìˆ˜ì§‘
    console.log('ğŸ™ï¸ MediaRecorder started for pronunciation assessment')
  }

  /**
   * ArrayBuffer â†’ Base64 ë³€í™˜
   * @private
   */
  arrayBufferToBase64(buffer) {
    let binary = ''
    const bytes = new Uint8Array(buffer)
    const len = bytes.byteLength
    for (let i = 0; i < len; i++) {
      binary += String.fromCharCode(bytes[i])
    }
    return window.btoa(binary)
  }

  /**
   * Blob â†’ Base64 ë³€í™˜ (deprecated - PCM ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´ë¨)
   * @private
   */
  async blobToBase64(blob) {
    return new Promise((resolve, reject) => {
      const reader = new FileReader()
      reader.onloadend = () => {
        // "data:audio/webm;base64,..." í˜•íƒœì—ì„œ base64 ë¶€ë¶„ë§Œ ì¶”ì¶œ
        const base64 = reader.result.split(',')[1]
        resolve(base64)
      }
      reader.onerror = reject
      reader.readAsDataURL(blob)
    })
  }

  /**
   * WebSocket OPEN ìƒíƒœ ëŒ€ê¸°
   * @private
   */
  waitForOpen() {
    return new Promise((resolve, reject) => {
      if (this.ws.readyState === WebSocket.OPEN) {
        resolve()
        return
      }

      const timeout = setTimeout(() => {
        reject(new Error('WebSocket ì—°ê²° íƒ€ì„ì•„ì›ƒ (10ì´ˆ)'))
      }, 10000)

      this.ws.onopen = () => {
        clearTimeout(timeout)
        resolve()
      }

      this.ws.onerror = () => {
        clearTimeout(timeout)
        reject(new Error('WebSocket ì—°ê²° ì‹¤íŒ¨'))
      }
    })
  }

  /**
   * ì¸ì¦ ì„±ê³µ ëŒ€ê¸°
   * @private
   */
  waitForAuthSuccess() {
    return new Promise((resolve, reject) => {
      const timeout = setTimeout(() => {
        reject(new Error('ì¸ì¦ íƒ€ì„ì•„ì›ƒ (10ì´ˆ)'))
      }, 10000)

      const originalOnMessage = this.ws.onmessage

      this.ws.onmessage = (event) => {
        try {
          const message = JSON.parse(event.data)

          if (message.type === 'auth_success') {
            clearTimeout(timeout)
            this.ws.onmessage = originalOnMessage  // ì›ë˜ í•¸ë“¤ëŸ¬ë¡œ ë³µêµ¬
            resolve()
          } else if (message.type === 'auth_error') {
            clearTimeout(timeout)
            reject(new Error(message.message || 'ì¸ì¦ ì‹¤íŒ¨'))
          }
        } catch (error) {
          // íŒŒì‹± ì—ëŸ¬ ë¬´ì‹œ (ë‹¤ë¥¸ ë©”ì‹œì§€ì¼ ìˆ˜ ìˆìŒ)
        }
      }
    })
  }

  /**
   * ë…¹ìŒ ì¤‘ì§€ ë° WebSocket ì¢…ë£Œ
   * @returns {Promise<Blob|null>} ë°œìŒ í‰ê°€ìš© ì˜¤ë””ì˜¤ Blob
   */
  async stopStreaming() {
    console.log('â¹ï¸ Stopping streaming...')

    try {
      // Stop ì‹ í˜¸ ì „ì†¡
      if (this.ws && this.ws.readyState === WebSocket.OPEN) {
        this.ws.send(JSON.stringify({ type: 'stop' }))
        console.log('ğŸ“¤ Stop signal sent')
      }
    } catch (error) {
      console.error('Stop signal send failed:', error)
    }

    // ë°œìŒ í‰ê°€ìš© MediaRecorder ì¤‘ì§€ ë° Blob ìƒì„±
    let audioBlob = null
    if (this.mediaRecorderForPronunciation && this.mediaRecorderForPronunciation.state !== 'inactive') {
      audioBlob = await new Promise((resolve) => {
        this.mediaRecorderForPronunciation.onstop = () => {
          if (this.audioChunks.length > 0) {
            const blob = new Blob(this.audioChunks, { type: 'audio/webm' })
            console.log(`ğŸ¤ Audio blob created for pronunciation: ${blob.size} bytes`)
            resolve(blob)
          } else {
            console.warn('âš ï¸ No audio chunks collected')
            resolve(null)
          }
        }
        this.mediaRecorderForPronunciation.stop()
      })
    }

    this.cleanup()
    this.isRecording = false

    console.log('âœ… Streaming stopped')

    return audioBlob
  }

  /**
   * ë¦¬ì†ŒìŠ¤ ì •ë¦¬
   * @private
   */
  cleanup() {
    // AudioContext ì •ë¦¬
    if (this.scriptNode) {
      try {
        this.scriptNode.disconnect()
      } catch (error) {
        console.error('ScriptNode disconnect error:', error)
      }
      this.scriptNode = null
    }

    if (this.source) {
      try {
        this.source.disconnect()
      } catch (error) {
        console.error('Source disconnect error:', error)
      }
      this.source = null
    }

    if (this.audioContext) {
      try {
        this.audioContext.close()
      } catch (error) {
        console.error('AudioContext close error:', error)
      }
      this.audioContext = null
    }

    // MediaRecorder ì •ë¦¬ (deprecated)
    if (this.mediaRecorder && this.mediaRecorder.state !== 'inactive') {
      try {
        this.mediaRecorder.stop()
      } catch (error) {
        console.error('MediaRecorder stop error:', error)
      }
    }
    this.mediaRecorder = null

    // ë°œìŒ í‰ê°€ìš© MediaRecorder ì •ë¦¬
    if (this.mediaRecorderForPronunciation && this.mediaRecorderForPronunciation.state !== 'inactive') {
      try {
        this.mediaRecorderForPronunciation.stop()
      } catch (error) {
        console.error('MediaRecorder for pronunciation stop error:', error)
      }
    }
    this.mediaRecorderForPronunciation = null
    this.audioChunks = []

    // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
    if (this.stream) {
      this.stream.getTracks().forEach(track => {
        track.stop()
      })
      this.stream = null
    }

    // WebSocket ì •ë¦¬
    if (this.ws) {
      if (this.ws.readyState === WebSocket.OPEN || this.ws.readyState === WebSocket.CONNECTING) {
        try {
          this.ws.close()
        } catch (error) {
          console.error('WebSocket close error:', error)
        }
      }
      this.ws = null
    }

    this.isRecording = false
  }

  /**
   * ë…¹ìŒ ì¤‘ ì—¬ë¶€
   * @returns {boolean}
   */
  getIsRecording() {
    return this.isRecording
  }

  /**
   * ë¸Œë¼ìš°ì € ì§€ì› ì—¬ë¶€ í™•ì¸
   * @returns {boolean}
   */
  static isSupported() {
    return !!(
      navigator.mediaDevices &&
      navigator.mediaDevices.getUserMedia &&
      window.MediaRecorder &&
      window.WebSocket
    )
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ export
export default new VoiceSTTStreamService()
