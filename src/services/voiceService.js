/**
 * Voice API ì„œë¹„ìŠ¤
 *
 * ë°±ì—”ë“œ Voice API (STT, Translation, TTS)ë¥¼ í˜¸ì¶œí•˜ëŠ” ì„œë¹„ìŠ¤
 * WebSocket STT ìŠ¤íŠ¸ë¦¬ë° ë° REST API ì§€ì›
 *
 * ì£¼ìš” ê¸°ëŠ¥:
 * - WebSocket ê¸°ë°˜ ì‹¤ì‹œê°„ STT ìŠ¤íŠ¸ë¦¬ë°
 * - REST API ê¸°ë°˜ ë²ˆì—­
 * - REST API ê¸°ë°˜ TTS (ìŒì„± í•©ì„±)
 */
import api from './api'

const BASE_URL = '/ai/voice'

/**
 * STT: ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (POST ì—…ë¡œë“œ)
 *
 * @param {File} audioFile - ìŒì„± íŒŒì¼ (WAV/MP3/OGG)
 * @param {string} language - BCP-47 ì–¸ì–´ ì½”ë“œ (ì˜ˆ: ko-KR, en-US, ja-JP)
 * @param {boolean} enableDiarization - í™”ì ë¶„ë¦¬ í™œì„±í™” ì—¬ë¶€
 * @returns {Promise<Object>} STT ê²°ê³¼ { text, speaker_id, confidence, language }
 */
export async function speechToText(audioFile, language = 'ko-KR', enableDiarization = true) {
  const formData = new FormData()
  formData.append('file', audioFile)
  formData.append('language', language)
  formData.append('enable_diarization', enableDiarization)

  const response = await api.post(`${BASE_URL}/stt`, formData, {
    headers: {
      'Content-Type': 'multipart/form-data'
    }
  })

  return response.data.data
}

/**
 * WebSocket STT ìŠ¤íŠ¸ë¦¬ë° ì—°ê²° ìƒì„±
 *
 * @param {string} language - BCP-47 ì–¸ì–´ ì½”ë“œ
 * @param {boolean} enableDiarization - í™”ì ë¶„ë¦¬ í™œì„±í™”
 * @param {Object} callbacks - ì´ë²¤íŠ¸ ì½œë°± í•¨ìˆ˜
 * @param {Function} callbacks.onRecognizing - ì¤‘ê°„ ì¸ì‹ ê²°ê³¼ ì½œë°±
 * @param {Function} callbacks.onRecognized - ìµœì¢… ì¸ì‹ ê²°ê³¼ ì½œë°±
 * @param {Function} callbacks.onError - ì—ëŸ¬ ì½œë°±
 * @param {Function} callbacks.onEnd - ì¢…ë£Œ ì½œë°±
 * @returns {Object} WebSocket ë° ì œì–´ í•¨ìˆ˜ { ws, send, close }
 */
export function createSTTStream(language = 'ko-KR', enableDiarization = true, callbacks = {}) {
  // WebSocket URL ìƒì„±
  const wsProtocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:'
  const wsHost = import.meta.env.VITE_API_URL
    ? new URL(import.meta.env.VITE_API_URL).host
    : 'localhost:8000'
  const wsUrl = `${wsProtocol}//${wsHost}${BASE_URL}/stt/stream`

  // WebSocket ì—°ê²°
  const ws = new WebSocket(wsUrl)

  // ì—°ê²° ì„±ê³µ ì‹œ ì´ˆê¸° ì„¤ì • ì „ì†¡
  ws.onopen = () => {
    console.log('âœ… WebSocket STT connected')
    ws.send(JSON.stringify({
      language,
      enable_diarization: enableDiarization
    }))
  }

  // ë©”ì‹œì§€ ìˆ˜ì‹ 
  ws.onmessage = (event) => {
    try {
      const message = JSON.parse(event.data)

      switch (message.type) {
        case 'recognizing':
          // ì¤‘ê°„ ì¸ì‹ ê²°ê³¼
          if (callbacks.onRecognizing) {
            callbacks.onRecognizing(message)
          }
          break

        case 'recognized':
          // ìµœì¢… ì¸ì‹ ê²°ê³¼
          if (callbacks.onRecognized) {
            callbacks.onRecognized(message)
          }
          break

        case 'error':
          // ì—ëŸ¬
          console.error('âŒ STT error:', message.error)
          if (callbacks.onError) {
            callbacks.onError(message.error)
          }
          break

        case 'end':
          // ì¢…ë£Œ
          console.log('ğŸ”š STT stream ended')
          if (callbacks.onEnd) {
            callbacks.onEnd()
          }
          break

        default:
          console.warn('Unknown message type:', message.type)
      }
    } catch (error) {
      console.error('Failed to parse WebSocket message:', error)
      if (callbacks.onError) {
        callbacks.onError(error.message)
      }
    }
  }

  // ì—°ê²° ì¢…ë£Œ
  ws.onclose = () => {
    console.log('ğŸ”Œ WebSocket STT disconnected')
    if (callbacks.onEnd) {
      callbacks.onEnd()
    }
  }

  // ì—ëŸ¬
  ws.onerror = (error) => {
    console.error('âŒ WebSocket error:', error)
    if (callbacks.onError) {
      callbacks.onError(error.message || 'WebSocket error')
    }
  }

  // ì œì–´ í•¨ìˆ˜ ë°˜í™˜
  return {
    ws,

    /**
     * ì˜¤ë””ì˜¤ ì²­í¬ ì „ì†¡
     * @param {Blob|ArrayBuffer} audioChunk - ì˜¤ë””ì˜¤ ë°ì´í„°
     */
    send(audioChunk) {
      if (ws.readyState === WebSocket.OPEN) {
        ws.send(audioChunk)
      } else {
        console.warn('WebSocket is not open. Ready state:', ws.readyState)
      }
    },

    /**
     * WebSocket ì—°ê²° ì¢…ë£Œ
     */
    close() {
      if (ws.readyState === WebSocket.OPEN) {
        // ì¢…ë£Œ ë©”ì‹œì§€ ì „ì†¡
        ws.send(JSON.stringify({ type: 'end' }))
        // WebSocket ë‹«ê¸°
        setTimeout(() => ws.close(), 100)
      } else {
        ws.close()
      }
    }
  }
}

/**
 * ë²ˆì—­: í…ìŠ¤íŠ¸ë¥¼ ë‹¤ë¥¸ ì–¸ì–´ë¡œ ë²ˆì—­
 *
 * @param {string} text - ë²ˆì—­í•  í…ìŠ¤íŠ¸
 * @param {string} sourceLang - ì›ë³¸ ì–¸ì–´ (ISO 639-1, ì˜ˆ: ko, en, ja)
 * @param {string} targetLang - ëª©í‘œ ì–¸ì–´ (ISO 639-1)
 * @returns {Promise<Object>} ë²ˆì—­ ê²°ê³¼ { original_text, translated_text, source_lang, target_lang }
 */
export async function translateText(text, sourceLang = 'ko', targetLang = 'en') {
  const response = await api.post(`${BASE_URL}/translate`, {
    text,
    source_lang: sourceLang,
    target_lang: targetLang
  })

  return response.data.data
}

/**
 * ì¼ê´„ ë²ˆì—­: ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ë²ˆì—­
 *
 * @param {string[]} texts - ë²ˆì—­í•  í…ìŠ¤íŠ¸ ë°°ì—´ (ìµœëŒ€ 100ê°œ)
 * @param {string} sourceLang - ì›ë³¸ ì–¸ì–´
 * @param {string} targetLang - ëª©í‘œ ì–¸ì–´
 * @returns {Promise<Object>} ë²ˆì—­ ê²°ê³¼ { translations[], total_count }
 */
export async function translateBatch(texts, sourceLang = 'ko', targetLang = 'en') {
  const response = await api.post(`${BASE_URL}/translate/batch`, {
    texts,
    source_lang: sourceLang,
    target_lang: targetLang
  })

  return response.data.data
}

/**
 * ì§€ì› ì–¸ì–´ ëª©ë¡ ì¡°íšŒ
 *
 * @returns {Promise<Object>} ì§€ì› ì–¸ì–´ ëª©ë¡ { languages: {}, total_count }
 */
export async function getSupportedLanguages() {
  const response = await api.get(`${BASE_URL}/translate/languages`)
  return response.data.data
}

/**
 * TTS: í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
 *
 * @param {string} text - ìŒì„±ìœ¼ë¡œ ë³€í™˜í•  í…ìŠ¤íŠ¸
 * @param {string} voiceName - Azure ë‰´ëŸ´ ìŒì„± ì´ë¦„ (ì˜ˆ: ko-KR-SunHiNeural)
 * @param {number} rate - ë§í•˜ê¸° ì†ë„ (0.5 ~ 2.0, ê¸°ë³¸ê°’ 1.0)
 * @param {number} pitch - ìŒë†’ì´ (-50 ~ 50, ê¸°ë³¸ê°’ 0)
 * @param {number} volume - ìŒëŸ‰ (0 ~ 100, ê¸°ë³¸ê°’ 100)
 * @returns {Promise<Blob>} WAV í˜•ì‹ ì˜¤ë””ì˜¤ Blob
 */
export async function textToSpeech(
  text,
  voiceName = 'ko-KR-SunHiNeural',
  rate = 1.0,
  pitch = 0,
  volume = 100
) {
  const response = await api.post(
    `${BASE_URL}/tts`,
    {
      text,
      voice_name: voiceName,
      rate,
      pitch,
      volume
    },
    {
      responseType: 'blob' // ë°”ì´ë„ˆë¦¬ ì‘ë‹µ
    }
  )

  // Blob ë°˜í™˜ (WAV í˜•ì‹)
  return new Blob([response.data], { type: 'audio/wav' })
}

/**
 * ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡ ì¡°íšŒ
 *
 * @returns {Promise<Object>} ìŒì„± ëª©ë¡ { voices: {}, total_languages, total_voices }
 */
export async function getAvailableVoices() {
  const response = await api.get(`${BASE_URL}/tts/voices`)
  return response.data.data
}
